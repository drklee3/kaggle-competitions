{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18793371",
   "metadata": {},
   "source": [
    "# LLM Classification Finetuning\n",
    "\n",
    "Competition: https://www.kaggle.com/competitions/llm-classification-finetuning/overview\n",
    "\n",
    "## Submission File\n",
    "\n",
    "For each ID in the test set, you must predict the probability for each target class. The file should contain a header and have the following format:\n",
    "\n",
    "```csv\n",
    "id,winner_model_a,winner_model_b,winner_tie\n",
    "136060,0.33,0,33,0.33\n",
    "211333,0.33,0,33,0.33\n",
    "1233961,0.33,0,33,0.33\n",
    "etc\n",
    "```\n",
    "\n",
    "Submission file must be named `submission.csv` in the `/kaggle/working/` directory.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Input files are in `/kaggle/input/llm-classification-finetuning/` directory if\n",
    "running on Kaggle.\n",
    "\n",
    "```\n",
    "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
    "/kaggle/input/llm-classification-finetuning/train.csv\n",
    "/kaggle/input/llm-classification-finetuning/test.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c343d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE_KERNEL_RUN_TYPE: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "kaggle_run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE')\n",
    "print(f\"KAGGLE_KERNEL_RUN_TYPE: {kaggle_run_type}\")\n",
    "\n",
    "ON_KAGGLE = kaggle_run_type is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0893984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base path: ./data/\n",
      "Available files in base path:\n",
      " - ./data/test.csv\n",
      " - ./data/sample_submission.csv\n",
      " - ./data/train.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning' if ON_KAGGLE else './data/'\n",
    "\n",
    "print(f\"Using base path: {BASE_PATH}\")\n",
    "\n",
    "print(\"Available files in base path:\")\n",
    "for root, dirs, files in os.walk(BASE_PATH):\n",
    "    for file in files:\n",
    "        print(f\" - {os.path.join(root, file)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acea90a",
   "metadata": {},
   "source": [
    "# Data Inputs\n",
    "\n",
    "Let's load and look at what we got first for inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54101227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: tabulate in /root/miniconda3/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3410a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "sample_submission_df = pd.read_csv(os.path.join(BASE_PATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e59919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (57477, 9)\n",
      "Test DataFrame shape: (3, 4)\n",
      "Sample Submission DataFrame shape: (3, 4)\n",
      "-------------------------\n",
      "\n",
      "Column types in Train DataFrame:\n",
      "id                 int64\n",
      "model_a           object\n",
      "model_b           object\n",
      "prompt            object\n",
      "response_a        object\n",
      "response_b        object\n",
      "winner_model_a     int64\n",
      "winner_model_b     int64\n",
      "winner_tie         int64\n",
      "dtype: object\n",
      "\n",
      "Column types in Test DataFrame:\n",
      "id             int64\n",
      "prompt        object\n",
      "response_a    object\n",
      "response_b    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
    "print(f\"Sample Submission DataFrame shape: {sample_submission_df.shape}\")\n",
    "\n",
    "print (\"-------------------------\")\n",
    "# Print types of each column\n",
    "print(\"\\nColumn types in Train DataFrame:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nColumn types in Test DataFrame:\")\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c30020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of each DataFrame:\n",
      "\n",
      "Train DataFrame:\n",
      "|    |    id | model_a            | model_b    | prompt                                                                                                                                                                | response_a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | response_b                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   winner_model_a |   winner_model_b |   winner_tie |\n",
      "|---:|------:|:-------------------|:-----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------:|-----------------:|-------------:|\n",
      "|  0 | 30192 | gpt-4-1106-preview | gpt-4-0613 | [\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"] | [\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"] | [\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"] |                1 |                0 |            0 |\n",
      "\n",
      "Test DataFrame:\n",
      "|    |     id | prompt                                                                                 | response_a                      | response_b                                                                                                         |\n",
      "|---:|-------:|:---------------------------------------------------------------------------------------|:--------------------------------|:-------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | 136060 | [\"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\"] | [\"You have two oranges today.\"] | [\"You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\"] |\n",
      "\n",
      "Sample Submission DataFrame:\n",
      "|    |     id |   winner_model_a |   winner_model_b |   winner_tie |\n",
      "|---:|-------:|-----------------:|-----------------:|-------------:|\n",
      "|  0 | 136060 |         0.333333 |         0.333333 |     0.333333 |\n"
     ]
    }
   ],
   "source": [
    "print(\"First rows of each DataFrame:\")\n",
    "\n",
    "print(\"\\nTrain DataFrame:\")\n",
    "print(train_df.head(1).to_markdown())\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head(1).to_markdown())\n",
    "\n",
    "print(\"\\nSample Submission DataFrame:\")\n",
    "print(sample_submission_df.head(1).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733242b",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "Ok I think we now can load the huggingface stuff to create the datasets from the\n",
    "pandas dataframes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b45f04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 51729\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 5748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Split the train dataset into train and validation sets, since the test.csv data only has 3 rows.\n",
    "train_dataset = train_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "# Can see it's now a DatasetDict with 'train' and 'test' splits\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7501",
   "metadata": {},
   "source": [
    "## The model stuff now?\n",
    "\n",
    "We need to pick:\n",
    "- Model\n",
    "- Fine tuning method\n",
    "\n",
    "Let's start small:\n",
    "- smol-lm\n",
    "- prompt tuning with `peft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba612b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: evaluate in /root/miniconda3/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: peft in /root/miniconda3/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: dill in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /root/miniconda3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: dill in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /root/miniconda3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/lib/python3.10/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/lib/python3.10/site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/lib/python3.10/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/lib/python3.10/site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers evaluate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5737f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code:\n",
      "def print_hello_world():\n",
      "    print(\"Hello World!\")\n",
      "\n",
      "def print_hello_world_with_print():\n",
      "   \n",
      "---------------\n",
      "Memory footprint: 538.06 MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "# why is it none tho\n",
    "assert model.config.pad_token_id is None\n",
    "assert tokenizer.eos_token is not None, \"Tokenizer must have an eos_token set.\"\n",
    "\n",
    "# set the pad token to be the same as the eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "inputs = tokenizer.encode(\"def print_hello_world():\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs)\n",
    "\n",
    "print(\"Generated code:\")\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "print(\"---------------\")\n",
    "\n",
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3294d80",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "Note that columns `prompt`, `response_a`, and `response_b` are strings\n",
    "containing JSON arrays that could have more than 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df57e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row with >1 element: row 1: ['It looks like there might be a typo in your code. The property for getting the number of elements in an array is `length`, not `lenght`. Also, when you\\'re importing a module, you should use the `import` statement correctly with curly braces `{}` around named exports unless you are importing the default export. Here\\'s the corrected line of code:\\n\\n```javascript\\nimport { cards } from \"./cards.js\";\\ndocument.querySelector(\"#result > span\").textContent = cards.length - quizTable.length;\\n```\\n\\nMake sure that `quizTable` is also defined and imported if necessary, as it\\'s being used but not shown in the snippet you provided. If it\\'s a variable that holds an array in the current scope, then it should work fine with the corrected `length` property.', \"Pour enlever la dernière valeur d'un tableau en JavaScript, vous pouvez utiliser la méthode `pop()`. Voici un exemple :\\n\\n```javascript\\nlet monTableau = [1, 2, 3, 4, 5];\\nmonTableau.pop(); // Cela enlève le dernier élément du tableau, qui est 5 dans cet exemple.\\n\\nconsole.log(monTableau); // Affichera [1, 2, 3, 4] dans la console.\\n```\\n\\nLa méthode `pop()` modifie le tableau original en retirant le dernier élément et renvoie cet élément. Si le tableau est vide, `pop()` renvoie `undefined`.\", \"Pour enlever une valeur spécifique d'un tableau en JavaScript, vous pouvez utiliser diverses méthodes, en fonction de votre besoin. Voici quelques exemples courants :\\n\\n1. **Enlever un élément par son index avec `splice()`:**\\n\\n   Si vous connaissez l'index de l'élément que vous souhaitez retirer, vous pouvez utiliser la méthode `splice()`. Elle permet de retirer un ou plusieurs éléments à partir d'un index donné.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let indexASupprimer = 2; // Pour enlever 'c'\\n   monTableau.splice(indexASupprimer, 1); // Le second paramètre indique le nombre d'éléments à supprimer\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n2. **Enlever un élément par sa valeur avec `filter()`:**\\n\\n   Si vous ne connaissez pas l'index de l'élément mais sa valeur, vous pouvez utiliser la méthode `filter()` pour créer un nouveau tableau sans cet élément.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let valeurASupprimer = 'c';\\n   monTableau = monTableau.filter(item => item !== valeurASupprimer);\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n3. **Enlever plusieurs occurrences d'une valeur avec `filter()`:**\\n\\n   Si la valeur à supprimer peut se trouver plusieurs fois dans le tableau et que vous souhaitez enlever toutes ses occurrences, vous pouvez également utiliser `filter()`.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'c', 'd', 'e', 'c'];\\n   let valeurASupprimer = 'c';\\n   monTableau = monTableau.filter(item => item !== valeurASupprimer);\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n4. **Enlever un élément par son index avec `slice()`:**\\n\\n   Si vous souhaitez enlever un élément sans modifier le tableau original, vous pouvez combiner `slice()` pour créer une copie du tableau sans l'élément.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let indexASupprimer = 2;\\n   let nouveauTableau = [...monTableau.slice(0, indexASupprimer), ...monTableau.slice(indexASupprimer + 1)];\\n\\n   console.log(nouveauTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\nNotez que `splice()` modifie le tableau original, tandis que `filter()` et `slice()` renvoient un nouveau tableau sans modifier l'original.\"]\n",
      "\n",
      "Row detail:\n",
      "{\n",
      "  \"id\": 1230081540,\n",
      "  \"model_a\": \"gpt-4-1106-preview\",\n",
      "  \"model_b\": \"gpt-3.5-turbo-1106\",\n",
      "  \"prompt\": [\n",
      "    \"corriger : import cards from \\\"./cards.js\\\";\\ndocument.querySelector(\\\"#result > span\\\").textContent = cards.lenght - quizTable.length;\",\n",
      "    \"enlever la derni\\u00e8re valeur d'un tableau en javascript\",\n",
      "    \"enlever une valeur dans un tableau\"\n",
      "  ],\n",
      "  \"response_a\": [\n",
      "    \"It looks like there might be a typo in your code. The property for getting the number of elements in an array is `length`, not `lenght`. Also, when you're importing a module, you should use the `import` statement correctly with curly braces `{}` around named exports unless you are importing the default export. Here's the corrected line of code:\\n\\n```javascript\\nimport { cards } from \\\"./cards.js\\\";\\ndocument.querySelector(\\\"#result > span\\\").textContent = cards.length - quizTable.length;\\n```\\n\\nMake sure that `quizTable` is also defined and imported if necessary, as it's being used but not shown in the snippet you provided. If it's a variable that holds an array in the current scope, then it should work fine with the corrected `length` property.\",\n",
      "    \"Pour enlever la derni\\u00e8re valeur d'un tableau en JavaScript, vous pouvez utiliser la m\\u00e9thode `pop()`. Voici un exemple :\\n\\n```javascript\\nlet monTableau = [1, 2, 3, 4, 5];\\nmonTableau.pop(); // Cela enl\\u00e8ve le dernier \\u00e9l\\u00e9ment du tableau, qui est 5 dans cet exemple.\\n\\nconsole.log(monTableau); // Affichera [1, 2, 3, 4] dans la console.\\n```\\n\\nLa m\\u00e9thode `pop()` modifie le tableau original en retirant le dernier \\u00e9l\\u00e9ment et renvoie cet \\u00e9l\\u00e9ment. Si le tableau est vide, `pop()` renvoie `undefined`.\",\n",
      "    \"Pour enlever une valeur sp\\u00e9cifique d'un tableau en JavaScript, vous pouvez utiliser diverses m\\u00e9thodes, en fonction de votre besoin. Voici quelques exemples courants :\\n\\n1. **Enlever un \\u00e9l\\u00e9ment par son index avec `splice()`:**\\n\\n   Si vous connaissez l'index de l'\\u00e9l\\u00e9ment que vous souhaitez retirer, vous pouvez utiliser la m\\u00e9thode `splice()`. Elle permet de retirer un ou plusieurs \\u00e9l\\u00e9ments \\u00e0 partir d'un index donn\\u00e9.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let indexASupprimer = 2; // Pour enlever 'c'\\n   monTableau.splice(indexASupprimer, 1); // Le second param\\u00e8tre indique le nombre d'\\u00e9l\\u00e9ments \\u00e0 supprimer\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n2. **Enlever un \\u00e9l\\u00e9ment par sa valeur avec `filter()`:**\\n\\n   Si vous ne connaissez pas l'index de l'\\u00e9l\\u00e9ment mais sa valeur, vous pouvez utiliser la m\\u00e9thode `filter()` pour cr\\u00e9er un nouveau tableau sans cet \\u00e9l\\u00e9ment.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let valeurASupprimer = 'c';\\n   monTableau = monTableau.filter(item => item !== valeurASupprimer);\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n3. **Enlever plusieurs occurrences d'une valeur avec `filter()`:**\\n\\n   Si la valeur \\u00e0 supprimer peut se trouver plusieurs fois dans le tableau et que vous souhaitez enlever toutes ses occurrences, vous pouvez \\u00e9galement utiliser `filter()`.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'c', 'd', 'e', 'c'];\\n   let valeurASupprimer = 'c';\\n   monTableau = monTableau.filter(item => item !== valeurASupprimer);\\n\\n   console.log(monTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\n4. **Enlever un \\u00e9l\\u00e9ment par son index avec `slice()`:**\\n\\n   Si vous souhaitez enlever un \\u00e9l\\u00e9ment sans modifier le tableau original, vous pouvez combiner `slice()` pour cr\\u00e9er une copie du tableau sans l'\\u00e9l\\u00e9ment.\\n\\n   ```javascript\\n   let monTableau = ['a', 'b', 'c', 'd', 'e'];\\n   let indexASupprimer = 2;\\n   let nouveauTableau = [...monTableau.slice(0, indexASupprimer), ...monTableau.slice(indexASupprimer + 1)];\\n\\n   console.log(nouveauTableau); // Affichera ['a', 'b', 'd', 'e']\\n   ```\\n\\nNotez que `splice()` modifie le tableau original, tandis que `filter()` et `slice()` renvoient un nouveau tableau sans modifier l'original.\"\n",
      "  ],\n",
      "  \"response_b\": [\n",
      "    \"Correction : \\n```javascript\\nimport cards from \\\"./cards.js\\\";\\ndocument.querySelector(\\\"#result > span\\\").textContent = cards.length - quizTable.length;\\n```\",\n",
      "    \"Pour enlever la derni\\u00e8re valeur d'un tableau en JavaScript, vous pouvez utiliser la m\\u00e9thode `pop()`. Voici un exemple :\\n\\n```javascript\\nlet tableau = [1, 2, 3, 4, 5];\\ntableau.pop(); // Enl\\u00e8ve la derni\\u00e8re valeur du tableau\\nconsole.log(tableau); // Affiche [1, 2, 3, 4]\\n```\",\n",
      "    \"Pour supprimer une valeur sp\\u00e9cifique dans un tableau en JavaScript, vous pouvez utiliser la m\\u00e9thode `splice()`. Voici un exemple :\\n\\n```javascript\\nlet tableau = [1, 2, 3, 4, 5];\\nlet index = tableau.indexOf(3); // Trouve l'index de la valeur \\u00e0 supprimer\\nif (index !== -1) {\\n  tableau.splice(index, 1); // Supprime la valeur \\u00e0 l'index sp\\u00e9cifi\\u00e9\\n}\\nconsole.log(tableau); // Affiche [1, 2, 4, 5]\\n```\"\n",
      "  ],\n",
      "  \"winner_model_a\": 1,\n",
      "  \"winner_model_b\": 0,\n",
      "  \"winner_tie\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# grab the column as a plain Python list of strings\n",
    "col = train_dataset[\"train\"][\"response_a\"]\n",
    "\n",
    "# find the first row with multiple items\n",
    "first_multi = next(\n",
    "    (\n",
    "        (i, arr)\n",
    "        for i, raw in enumerate(col)\n",
    "        for arr in [json.loads(raw)]\n",
    "        if isinstance(arr, list) and len(arr) > 1\n",
    "    ),\n",
    "    None\n",
    ")\n",
    "\n",
    "if first_multi:\n",
    "    i, arr = first_multi\n",
    "    print(f\"First row with >1 element: row {i}: {arr}\")\n",
    "\n",
    "    # now pretty-print the full row at index i\n",
    "    row = train_dataset[\"train\"][i].copy()\n",
    "\n",
    "    # parse the JSON-encoded fields\n",
    "    row[\"prompt\"]     = json.loads(row[\"prompt\"])\n",
    "    row[\"response_a\"] = arr\n",
    "    row[\"response_b\"] = json.loads(row[\"response_b\"])\n",
    "\n",
    "    print(\"\\nRow detail:\")\n",
    "    print(json.dumps(row, indent=2))\n",
    "else:\n",
    "    print(\"No rows with >1 element found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf73e4",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Now i want to format the input training data to be an input to the model.\n",
    "\n",
    "Note that there can be multi-turn conversations.\n",
    "This will be a text input with the following format:\n",
    "\n",
    "```text\n",
    "## Turn 1\n",
    "### Prompt\n",
    "<prompt[0]>\n",
    "\n",
    "### Response A\n",
    "<response_a[0]>\n",
    "\n",
    "### Response B\n",
    "<response_b[0]>\n",
    "\n",
    "## Turn 2\n",
    "### Prompt\n",
    "<prompt[1]>\n",
    "\n",
    "### Response A\n",
    "<response_a[1]>\n",
    "\n",
    "### Response B\n",
    "<response_b[1]>\n",
    "\n",
    "---\n",
    "\n",
    "Which is better?\n",
    "Answer:\n",
    "```\n",
    "\n",
    "Where `<label>` is one of `a`, `b`, or `tie`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535dd3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_function() got an unexpected keyword argument 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Preprocess the first row as an example\u001b[39;00m\n\u001b[1;32m     81\u001b[0m example \u001b[38;5;241m=\u001b[39m train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 82\u001b[0m example_preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessed example:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_function() got an unexpected keyword argument 'max_length'"
     ]
    }
   ],
   "source": [
    "def preprocess_function(\n",
    "    examples,\n",
    "    tokenizer,\n",
    "    label_max_length: int = 4,\n",
    "):\n",
    "    # 1) Build the text inputs in the desired format\n",
    "    inputs = []\n",
    "    for prompt_json, response_a_json, response_b_json in zip(\n",
    "        examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"]\n",
    "    ):\n",
    "        # JSON decode the columns to handle multi-turn conversations\n",
    "        prompts = json.loads(prompt_json)\n",
    "        responses_a = json.loads(response_a_json)\n",
    "        responses_b = json.loads(response_b_json)\n",
    "        \n",
    "        # Build conversation with turn-by-turn format\n",
    "        conversation_parts = []\n",
    "        for i, (prompt_turn, response_a_turn, response_b_turn) in enumerate(zip(prompts, responses_a, responses_b), 1):\n",
    "            turn_text = f\"## Turn {i}\\n\"\n",
    "            turn_text += \"### Prompt\\n\"\n",
    "            turn_text += f\"{prompt_turn}\\n\\n\"\n",
    "\n",
    "            turn_text += \"### Response A\\n\"\n",
    "            turn_text += f\"{response_a_turn}\\n\\n\"\n",
    "\n",
    "            turn_text += \"### Response B\\n\"\n",
    "            turn_text += f\"{response_b_turn}\\n\"\n",
    "\n",
    "            conversation_parts.append(turn_text)\n",
    "        \n",
    "        # Join all turns with separator and add final question\n",
    "        conversation = \"\\n---\\n\\n\".join(conversation_parts)\n",
    "        input_text = f\"{conversation}\\n\\nWhich is better?\\nAnswer:\"\n",
    "        inputs.append(input_text)\n",
    "\n",
    "    # 2) Build the single‐char labels (\"a\", \"b\" or \"tie\")\n",
    "    targets = []\n",
    "    for wa, wb, wt in zip(\n",
    "        examples[\"winner_model_a\"],\n",
    "        examples[\"winner_model_b\"],\n",
    "        examples[\"winner_tie\"],\n",
    "    ):\n",
    "        if wa == 1:\n",
    "            targets.append(\"a\")\n",
    "        elif wb == 1:\n",
    "            targets.append(\"b\")\n",
    "        elif wt == 1:\n",
    "            targets.append(\"tie\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid winner values: must be one of a, b, or tie.\")\n",
    "\n",
    "    # 3) Tokenize the inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # 4) Tokenize the targets (labels)\n",
    "    label_tokens = tokenizer(\n",
    "        targets,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=label_max_length,\n",
    "    )\n",
    "\n",
    "    # 5) Replace all pad token ids in the labels with -100\n",
    "    labels = label_tokens[\"input_ids\"]\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    labels = [\n",
    "        [(-100 if token_id == pad_id else token_id) for token_id in seq]\n",
    "        for seq in labels\n",
    "    ]\n",
    "\n",
    "    # 6) Attach labels and return\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Preprocess the first row as an example\n",
    "\n",
    "example = train_dataset[\"train\"].select(range(1))\n",
    "example_preprocessed = preprocess_function(\n",
    "    example,\n",
    "    tokenizer=tokenizer,\n",
    "    label_max_length=4,\n",
    ")\n",
    "\n",
    "print(\"Preprocessed example:\")\n",
    "print(\"Input IDs:\")\n",
    "print(\"---------------------\")\n",
    "print(tokenizer.decode(example_preprocessed[\"input_ids\"][0]))\n",
    "\n",
    "# Remove -100 from labels for display\n",
    "labels = [token_id for token_id in example_preprocessed[\"labels\"][0] if token_id != -100]\n",
    "print(\"---------------------\")\n",
    "print(\"Decoded Labels:\")\n",
    "print(tokenizer.decode(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9572fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022d201a674f4416932704b5113c5894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51729 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "preprocess_function() missing 1 required positional argument: 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# optionally drop old columns\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/dataset_dict.py:944\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, with_split, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc, try_original_type)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[1;32m    942\u001b[0m     function \u001b[38;5;241m=\u001b[39m bind(function, split)\n\u001b[0;32m--> 944\u001b[0m dataset_dict[split] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_original_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_original_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[1;32m    966\u001b[0m     function \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3079\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3075\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3076\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3077\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3078\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3079\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3080\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3081\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3525\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3524\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3525\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[1;32m   3526\u001b[0m         num_examples_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(i)\n\u001b[1;32m   3527\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m update_data:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3475\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3474\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3475\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3398\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3396\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3397\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[0;32m-> 3398\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m ex: \u001b[43mpreprocess_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      3\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     remove_columns\u001b[38;5;241m=\u001b[39mtrain_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names,  \u001b[38;5;66;03m# optionally drop old columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_function() missing 1 required positional argument: 'max_length'"
     ]
    }
   ],
   "source": [
    "tokenized = train_dataset.map(\n",
    "    lambda ex: preprocess_function(ex, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset[\"train\"].column_names,  # optionally drop old columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
