{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230d5f6c",
   "metadata": {
    "papermill": {
     "duration": 0.005058,
     "end_time": "2025-06-20T00:48:26.744666",
     "exception": false,
     "start_time": "2025-06-20T00:48:26.739608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM Classification Finetuning\n",
    "\n",
    "Competition: https://www.kaggle.com/competitions/llm-classification-finetuning/overview\n",
    "\n",
    "## Submission File\n",
    "\n",
    "For each ID in the test set, you must predict the probability for each target class. The file should contain a header and have the following format:\n",
    "\n",
    "```csv\n",
    "id,winner_model_a,winner_model_b,winner_tie\n",
    "136060,0.33,0,33,0.33\n",
    "211333,0.33,0,33,0.33\n",
    "1233961,0.33,0,33,0.33\n",
    "etc\n",
    "```\n",
    "\n",
    "Submission file must be named `submission.csv` in the `/kaggle/working/` directory.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Input files are in `/kaggle/input/llm-classification-finetuning/` directory if\n",
    "running on Kaggle.\n",
    "\n",
    "```\n",
    "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
    "/kaggle/input/llm-classification-finetuning/train.csv\n",
    "/kaggle/input/llm-classification-finetuning/test.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4d88db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:48:26.754206Z",
     "iopub.status.busy": "2025-06-20T00:48:26.753938Z",
     "iopub.status.idle": "2025-06-20T00:48:26.761149Z",
     "shell.execute_reply": "2025-06-20T00:48:26.760459Z"
    },
    "papermill": {
     "duration": 0.013256,
     "end_time": "2025-06-20T00:48:26.762293",
     "exception": false,
     "start_time": "2025-06-20T00:48:26.749037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE_KERNEL_RUN_TYPE: Batch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "kaggle_run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE')\n",
    "print(f\"KAGGLE_KERNEL_RUN_TYPE: {kaggle_run_type}\")\n",
    "\n",
    "ON_KAGGLE = kaggle_run_type is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dea2425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:48:26.771411Z",
     "iopub.status.busy": "2025-06-20T00:48:26.771223Z",
     "iopub.status.idle": "2025-06-20T00:51:52.736717Z",
     "shell.execute_reply": "2025-06-20T00:51:52.735752Z"
    },
    "papermill": {
     "duration": 205.971587,
     "end_time": "2025-06-20T00:51:52.738105",
     "exception": false,
     "start_time": "2025-06-20T00:48:26.766518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\r\n",
      "Collecting pandas\r\n",
      "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tabulate\r\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\r\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting peft\r\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting wandb\r\n",
      "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting filelock (from torch)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\r\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting sympy>=1.13.3 (from torch)\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting jinja2 (from torch)\r\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\r\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\r\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting triton==3.3.1 (from torch)\r\n",
      "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting setuptools>=40.8.0 (from triton==3.3.1->torch)\r\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting numpy (from torchvision)\r\n",
      "  Downloading numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\r\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\r\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\r\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas)\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\r\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting packaging>=20.0 (from transformers)\r\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting pyyaml>=5.1 (from transformers)\r\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting regex!=2019.12.17 (from transformers)\r\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests (from transformers)\r\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\r\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers)\r\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting tqdm>=4.27 (from transformers)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\r\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting dill (from evaluate)\r\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting xxhash (from evaluate)\r\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from evaluate)\r\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\r\n",
      "Collecting psutil (from peft)\r\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting accelerate>=0.21.0 (from peft)\r\n",
      "  Downloading accelerate-1.8.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\r\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\r\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting platformdirs (from wandb)\r\n",
      "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\r\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\r\n",
      "Collecting pydantic<3 (from wandb)\r\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sentry-sdk>=2.0.0 (from wandb)\r\n",
      "  Downloading sentry_sdk-2.30.0-py2.py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting setproctitle (from wandb)\r\n",
      "  Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting dill (from evaluate)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting multiprocess (from evaluate)\r\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading aiohttp-3.12.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\r\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\r\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\r\n",
      "  Downloading hf_xet-1.1.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\r\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\r\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\r\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\r\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\r\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\r\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\r\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\r\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading multidict-6.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\r\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-1.8.0-py3-none-any.whl (365 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m749.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m152.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m75.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m351.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m362.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentry_sdk-2.30.0-py2.py3-none-any.whl (343 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.1/343.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\r\n",
      "Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\r\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp-3.12.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.7/157.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hf_xet-1.1.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multidict-6.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.5/213.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\r\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hSaved ./frozen_packages/torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl\r\n",
      "Saved ./frozen_packages/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\r\n",
      "Saved ./frozen_packages/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/tabulate-0.9.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/transformers-4.52.4-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/evaluate-0.4.3-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/peft-0.15.2-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/accelerate-1.8.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/click-8.2.1-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/datasets-3.6.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/dill-0.3.8-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/fsspec-2025.3.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/GitPython-3.1.44-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/huggingface_hub-0.33.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/multiprocess-0.70.16-py311-none-any.whl\r\n",
      "Saved ./frozen_packages/numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/packaging-25.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/pydantic-2.11.7-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/pytz-2025.2-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/requests-2.32.4-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/sentry_sdk-2.30.0-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/sympy-1.14.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/tqdm-4.67.1-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/typing_extensions-4.14.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/tzdata-2025.2-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/filelock-3.18.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/jinja2-3.1.6-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/networkx-3.5-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/platformdirs-4.3.8-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/aiohttp-3.12.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/annotated_types-0.7.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/certifi-2025.6.15-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/gitdb-4.0.12-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/hf_xet-1.1.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/idna-3.10-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/mpmath-1.3.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Saved ./frozen_packages/setuptools-80.9.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/six-1.17.0-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/typing_inspection-0.4.1-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/urllib3-2.5.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/aiohappyeyeballs-2.6.1-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/aiosignal-1.3.2-py2.py3-none-any.whl\r\n",
      "Saved ./frozen_packages/attrs-25.3.0-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/multidict-6.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Saved ./frozen_packages/smmap-5.0.2-py3-none-any.whl\r\n",
      "Saved ./frozen_packages/yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Successfully downloaded torch nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-cufile-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-cusparselt-cu12 nvidia-nccl-cu12 nvidia-nvjitlink-cu12 nvidia-nvtx-cu12 triton torchvision pandas tabulate transformers evaluate peft wandb accelerate click datasets dill fsspec gitpython huggingface-hub multiprocess numpy packaging pillow protobuf psutil pydantic pydantic-core python-dateutil pytz pyyaml regex requests safetensors sentry-sdk sympy tokenizers tqdm typing-extensions tzdata filelock jinja2 networkx platformdirs setproctitle xxhash aiohttp annotated-types certifi charset_normalizer gitdb hf-xet idna MarkupSafe mpmath pyarrow setuptools six typing-inspection urllib3 aiohappyeyeballs aiosignal attrs frozenlist multidict propcache smmap yarl\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in links: /kaggle/working/frozen_packages\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\r\n",
      "Processing ./frozen_packages/evaluate-0.4.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\r\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Processing ./frozen_packages/torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Processing ./frozen_packages/sympy-1.14.0-py3-none-any.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch)\r\n",
      "Processing ./frozen_packages/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from torch)\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\r\n",
      "Processing ./frozen_packages/torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\r\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\r\n",
      "Processing ./frozen_packages/fsspec-2025.3.0-py3-none-any.whl (from torch)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, evaluate\r\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\r\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\r\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\r\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.3.2\r\n",
      "    Uninstalling fsspec-2025.3.2:\r\n",
      "      Successfully uninstalled fsspec-2025.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 triton-3.3.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Download required packages - for re-use in inference notebook\n",
    "if ON_KAGGLE:\n",
    "    %pip download torch torchvision pandas tabulate transformers evaluate peft wandb \\\n",
    "        --dest /kaggle/working/frozen_packages \\\n",
    "        --prefer-binary \\\n",
    "    \n",
    "    # Install required packages\n",
    "    %pip install torch torchvision pandas tabulate transformers evaluate peft wandb \\\n",
    "        --find-links /kaggle/working/frozen_packages \\\n",
    "        --no-index\n",
    "\n",
    "else:\n",
    "    %pip install torch torchvision pandas tabulate transformers evaluate peft wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2e3271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:51:52.837478Z",
     "iopub.status.busy": "2025-06-20T00:51:52.836737Z",
     "iopub.status.idle": "2025-06-20T00:51:56.100669Z",
     "shell.execute_reply": "2025-06-20T00:51:56.099787Z"
    },
    "papermill": {
     "duration": 3.314055,
     "end_time": "2025-06-20T00:51:56.101932",
     "exception": false,
     "start_time": "2025-06-20T00:51:52.787877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrklee3\u001b[0m (\u001b[33mdrklee3-kava-labs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Setup wandb\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"llm-classification-ft-peft\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    os.environ[\"WANDB_HOST\"] = \"kaggle\"\n",
    "    \n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "    wandb.login(key=wandb_key)\n",
    "else:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186755e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:51:56.198980Z",
     "iopub.status.busy": "2025-06-20T00:51:56.198357Z",
     "iopub.status.idle": "2025-06-20T00:51:56.203602Z",
     "shell.execute_reply": "2025-06-20T00:51:56.202894Z"
    },
    "papermill": {
     "duration": 0.054804,
     "end_time": "2025-06-20T00:51:56.204626",
     "exception": false,
     "start_time": "2025-06-20T00:51:56.149822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base path: /kaggle/input/llm-classification-finetuning\n",
      "Available files in base path:\n",
      " - /kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      " - /kaggle/input/llm-classification-finetuning/train.csv\n",
      " - /kaggle/input/llm-classification-finetuning/test.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning' if ON_KAGGLE else './data/'\n",
    "\n",
    "print(f\"Using base path: {BASE_PATH}\")\n",
    "\n",
    "print(\"Available files in base path:\")\n",
    "for root, dirs, files in os.walk(BASE_PATH):\n",
    "    for file in files:\n",
    "        print(f\" - {os.path.join(root, file)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37efc724",
   "metadata": {
    "papermill": {
     "duration": 0.048437,
     "end_time": "2025-06-20T00:51:56.300739",
     "exception": false,
     "start_time": "2025-06-20T00:51:56.252302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Inputs\n",
    "\n",
    "Let's load and look at what we got first for inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76913cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:51:56.396237Z",
     "iopub.status.busy": "2025-06-20T00:51:56.395955Z",
     "iopub.status.idle": "2025-06-20T00:52:01.191381Z",
     "shell.execute_reply": "2025-06-20T00:52:01.190743Z"
    },
    "papermill": {
     "duration": 4.845012,
     "end_time": "2025-06-20T00:52:01.192661",
     "exception": false,
     "start_time": "2025-06-20T00:51:56.347649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
    "\n",
    "sample_submission_df = pd.read_csv(os.path.join(BASE_PATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923379d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:01.291158Z",
     "iopub.status.busy": "2025-06-20T00:52:01.290753Z",
     "iopub.status.idle": "2025-06-20T00:52:01.297441Z",
     "shell.execute_reply": "2025-06-20T00:52:01.296554Z"
    },
    "papermill": {
     "duration": 0.056433,
     "end_time": "2025-06-20T00:52:01.298628",
     "exception": false,
     "start_time": "2025-06-20T00:52:01.242195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (57477, 9)\n",
      "Test DataFrame shape: (3, 4)\n",
      "Sample Submission DataFrame shape: (3, 4)\n",
      "-------------------------\n",
      "\n",
      "Column types in Train DataFrame:\n",
      "id                 int64\n",
      "model_a           object\n",
      "model_b           object\n",
      "prompt            object\n",
      "response_a        object\n",
      "response_b        object\n",
      "winner_model_a     int64\n",
      "winner_model_b     int64\n",
      "winner_tie         int64\n",
      "dtype: object\n",
      "\n",
      "Column types in Test DataFrame:\n",
      "id             int64\n",
      "prompt        object\n",
      "response_a    object\n",
      "response_b    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
    "print(f\"Sample Submission DataFrame shape: {sample_submission_df.shape}\")\n",
    "\n",
    "print (\"-------------------------\")\n",
    "# Print types of each column\n",
    "print(\"\\nColumn types in Train DataFrame:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nColumn types in Test DataFrame:\")\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8799b51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:01.395362Z",
     "iopub.status.busy": "2025-06-20T00:52:01.394655Z",
     "iopub.status.idle": "2025-06-20T00:52:01.421744Z",
     "shell.execute_reply": "2025-06-20T00:52:01.421147Z"
    },
    "papermill": {
     "duration": 0.076722,
     "end_time": "2025-06-20T00:52:01.423381",
     "exception": false,
     "start_time": "2025-06-20T00:52:01.346659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of each DataFrame:\n",
      "\n",
      "Train DataFrame:\n",
      "|    |    id | model_a            | model_b    | prompt                                                                                                                                                                | response_a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | response_b                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   winner_model_a |   winner_model_b |   winner_tie |\n",
      "|---:|------:|:-------------------|:-----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------:|-----------------:|-------------:|\n",
      "|  0 | 30192 | gpt-4-1106-preview | gpt-4-0613 | [\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"] | [\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"] | [\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"] |                1 |                0 |            0 |\n",
      "\n",
      "Test DataFrame:\n",
      "|    |     id | prompt                                                                                 | response_a                      | response_b                                                                                                         |\n",
      "|---:|-------:|:---------------------------------------------------------------------------------------|:--------------------------------|:-------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | 136060 | [\"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\"] | [\"You have two oranges today.\"] | [\"You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\"] |\n",
      "\n",
      "Sample Submission DataFrame:\n",
      "|    |     id |   winner_model_a |   winner_model_b |   winner_tie |\n",
      "|---:|-------:|-----------------:|-----------------:|-------------:|\n",
      "|  0 | 136060 |         0.333333 |         0.333333 |     0.333333 |\n"
     ]
    }
   ],
   "source": [
    "print(\"First rows of each DataFrame:\")\n",
    "\n",
    "print(\"\\nTrain DataFrame:\")\n",
    "print(train_df.head(1).to_markdown())\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head(1).to_markdown())\n",
    "\n",
    "print(\"\\nSample Submission DataFrame:\")\n",
    "print(sample_submission_df.head(1).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210946e5",
   "metadata": {
    "papermill": {
     "duration": 0.047525,
     "end_time": "2025-06-20T00:52:01.519748",
     "exception": false,
     "start_time": "2025-06-20T00:52:01.472223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Dataset\n",
    "\n",
    "Ok I think we now can load the huggingface stuff to create the datasets from the\n",
    "pandas dataframes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df0a68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:01.621206Z",
     "iopub.status.busy": "2025-06-20T00:52:01.620473Z",
     "iopub.status.idle": "2025-06-20T00:52:04.234587Z",
     "shell.execute_reply": "2025-06-20T00:52:04.233845Z"
    },
    "papermill": {
     "duration": 2.665579,
     "end_time": "2025-06-20T00:52:04.235820",
     "exception": false,
     "start_time": "2025-06-20T00:52:01.570241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 51729\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 5748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Split the train dataset into train and validation sets, since the test.csv data only has 3 rows.\n",
    "train_dataset = train_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "# Can see it's now a DatasetDict with 'train' and 'test' splits\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85685cce",
   "metadata": {
    "papermill": {
     "duration": 0.047362,
     "end_time": "2025-06-20T00:52:04.332160",
     "exception": false,
     "start_time": "2025-06-20T00:52:04.284798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The model stuff now?\n",
    "\n",
    "We need to pick:\n",
    "- Model\n",
    "- Fine tuning method\n",
    "\n",
    "Let's start small:\n",
    "- smol-lm\n",
    "- prompt tuning with `peft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519529be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:04.430170Z",
     "iopub.status.busy": "2025-06-20T00:52:04.429395Z",
     "iopub.status.idle": "2025-06-20T00:52:33.508531Z",
     "shell.execute_reply": "2025-06-20T00:52:33.507636Z"
    },
    "papermill": {
     "duration": 29.12931,
     "end_time": "2025-06-20T00:52:33.509758",
     "exception": false,
     "start_time": "2025-06-20T00:52:04.380448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78615c7b860a4c29812a74bdd0f34e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cebfb2635940e08a621d40069536a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9ac3de4c064deea3abd7c96c8a5656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eb1ba3b2f14e6c8713cd705311012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b68da3415a48edb4972576a1082a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511a2407d9204687ab75e3c7f87b4190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:52:16.031686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750380736.251775      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750380736.313181      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae5acc4d3a418b8b6466107419dd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5a2b1b5acf4276b6d3f67654669635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code:\n",
      "def print_hello_world():\n",
      "    print(\"Hello World!\")\n",
      "\n",
      "def print_hello_world_with_print():\n",
      "   \n",
      "---------------\n",
      "Memory footprint: 538.06 MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "# why is it none tho\n",
    "assert model.config.pad_token_id is None\n",
    "assert tokenizer.eos_token is not None, \"Tokenizer must have an eos_token set.\"\n",
    "\n",
    "# set the pad token to be the same as the eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "inputs = tokenizer.encode(\"def print_hello_world():\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs)\n",
    "\n",
    "print(\"Generated code:\")\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "print(\"---------------\")\n",
    "\n",
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38133cb4",
   "metadata": {
    "papermill": {
     "duration": 0.048488,
     "end_time": "2025-06-20T00:52:33.609656",
     "exception": false,
     "start_time": "2025-06-20T00:52:33.561168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data format\n",
    "\n",
    "Note that columns `prompt`, `response_a`, and `response_b` are strings\n",
    "containing JSON arrays that could have more than 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f860f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:33.707543Z",
     "iopub.status.busy": "2025-06-20T00:52:33.706436Z",
     "iopub.status.idle": "2025-06-20T00:52:33.988533Z",
     "shell.execute_reply": "2025-06-20T00:52:33.987671Z"
    },
    "papermill": {
     "duration": 0.332545,
     "end_time": "2025-06-20T00:52:33.990091",
     "exception": false,
     "start_time": "2025-06-20T00:52:33.657546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row with >1 element: row 12: ['\"In recent years, there has been a significant increase in AI-powered solutions designed to address unmet medical needs, particularly in resource-limited settings and emerging regions like Africa. These advancements hold the potential to greatly enhance healthcare outcomes, accessibility, and efficiency. This report will delve into the development and application of AI-powered diagnostic tools, personalized treatment plans, and remote monitoring systems, underlining the importance of ethical considerations when employing these technologies.\\n\\nAI-Powered Diagnostic Tools: In settings with limited resources, the key to effective healthcare intervention lies in early detection and precise diagnoses. AI-powered diagnostic tools are emerging as a promising solution to this challenge. These tools leverage machine learning algorithms to analyze extensive datasets, thereby enabling healthcare professionals to detect diseases at an earlier stage with increased accuracy. For instance, image recognition algorithms have shown significant improvements in identifying diseases from radiology images, thus reducing dependence on specialist radiologists. By catalyzing early detection and accurate diagnoses, AI-powered diagnostic tools can substantially enhance healthcare outcomes in regions lacking sufficient medical expertise.\\n\\nPersonalized Treatment Plans: Customizing treatment plans to suit individual patient needs is fundamental for optimal healthcare outcomes. However, cultural and socioeconomic hurdles often impede access to personalized treatments in developing regions. AI and machine learning algorithms can dismantle these obstacles by assessing a broad spectrum of patient data, comprising genetic information, socioeconomic parameters, and cultural contexts. By integrating various facets of a patient\\'s life, these algorithms can suggest personalized treatment plans that are effective, suitable, and economically viable. Such an approach ensures that healthcare interventions are accessible and congruent with the local environment, thus improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems: Geographical barriers and inadequate healthcare infrastructure often pose significant difficulties for patients in developing regions.\"', 'Apologies for the oversight. Here is the corrected version with bolded changes.\\n\\n\"In recent years, there has been a significant **increase** in AI-powered solutions **designed** to address unmet medical needs, particularly in resource-limited settings and **emerging regions** like Africa. These advancements hold the potential to greatly **enhance** healthcare outcomes, accessibility, and efficiency. This report will **delve into** the development and application of AI-powered diagnostic tools, personalized treatment plans, and remote monitoring systems, **underlining** the importance of ethical considerations when employing these technologies.\\n\\nAI-Powered Diagnostic Tools: In settings with limited resources, the **key** to effective healthcare intervention lies in early detection and precise diagnoses. AI-powered diagnostic tools are emerging as a promising solution to this challenge. These tools **leverage** machine learning algorithms to **analyze** extensive datasets, thereby enabling healthcare professionals to detect diseases at an earlier stage with **increased** accuracy. For instance, image recognition algorithms have shown significant improvements in identifying diseases from radiology images, thus **reducing dependence** on specialist radiologists. By **catalyzing** early detection and accurate diagnoses, AI-powered diagnostic tools can substantially **enhance** healthcare outcomes in regions **lacking** sufficient medical expertise.\\n\\nPersonalized Treatment Plans: **Customizing** treatment plans to suit individual patient needs is fundamental for optimal healthcare outcomes. However, cultural and socioeconomic **hurdles** often impede access to personalized treatments in developing regions. AI and machine learning algorithms can **dismantle** these obstacles by assessing a broad **spectrum** of patient data, **comprising** genetic information, socioeconomic parameters, and cultural contexts. By **integrating** various facets of a patient\\'s life, these algorithms can suggest personalized treatment plans that are effective, suitable, and economically viable. Such an approach ensures that healthcare interventions are **accessible** and **congruent** with the local environment, thus improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems: **Geographical barriers** and **inadequate** healthcare infrastructure often pose significant difficulties for patients in developing regions.\"']\n",
      "\n",
      "Row detail:\n",
      "{\n",
      "  \"id\": 3259446547,\n",
      "  \"model_a\": \"gpt-4-0613\",\n",
      "  \"model_b\": \"llama-2-70b-chat\",\n",
      "  \"prompt\": [\n",
      "    \"Act as a business executive. Review the following business report and make necessary corrections to enhance its clarity, conciseness, and professionalism. Pay close attention to word choice, sentence structure, punctuation, and the logical flow of ideas. Additionally, consider adding or revising examples to support key points. Maintain a consistently professional tone throughout the report. Highlight all changes you make in bold font.\\n\\\" In recent years, there has been a surge in AI-powered solutions aimed at addressing unmet medical needs, especially in resource-limited settings and developing regions such as Africa. These advancements can significantly improve healthcare outcomes, accessibility, and efficiency. This section will explore the development and application of AI-powered diagnostic tools, personalised treatment plans, remote monitoring systems, and the importance of ethical considerations in using these technologies.\\nAI-Powered Diagnostic Tools: In resource-limited settings, early detection and accurate diagnoses are crucial for effective healthcare intervention. AI-powered diagnostic tools have emerged as a promising solution. These tools use machine learning algorithms to process large datasets, enabling healthcare professionals to detect diseases at earlier stages with higher accuracy rates. Image recognition algorithms, for instance, have progressed in identifying illness through radiology images, reducing the reliance on expert radiologists. By facilitating early detection and precise diagnoses, AI-powered diagnostic tools can significantly improve healthcare outcomes in regions with limited medical expertise.\\nPersonalised Treatment Plans: Tailoring treatment plans to each patient's needs is essential for the best healthcare outcomes. However, cultural and socio-economic challenges often hamper access to tailored treatments in developing regions. AI and machine learning algorithms can address these barriers by evaluating a wide range of patient data, including genetic information, socio-economic factors, and cultural context. By considering various aspects of a patient's life, these algorithms can recommend tailored treatment plans that are effective, appropriate, and economically feasible. This approach ensures that healthcare interventions are accessible and compatible with the local context, ultimately improving patient outcomes in resource-limited settings.\\nRemote Monitoring Systems: Geographical constraints and limited healthcare infrastructure make it difficult for patients in developing regi\",\n",
      "    \"nothing in bold?\"\n",
      "  ],\n",
      "  \"response_a\": [\n",
      "    \"\\\"In recent years, there has been a significant increase in AI-powered solutions designed to address unmet medical needs, particularly in resource-limited settings and emerging regions like Africa. These advancements hold the potential to greatly enhance healthcare outcomes, accessibility, and efficiency. This report will delve into the development and application of AI-powered diagnostic tools, personalized treatment plans, and remote monitoring systems, underlining the importance of ethical considerations when employing these technologies.\\n\\nAI-Powered Diagnostic Tools: In settings with limited resources, the key to effective healthcare intervention lies in early detection and precise diagnoses. AI-powered diagnostic tools are emerging as a promising solution to this challenge. These tools leverage machine learning algorithms to analyze extensive datasets, thereby enabling healthcare professionals to detect diseases at an earlier stage with increased accuracy. For instance, image recognition algorithms have shown significant improvements in identifying diseases from radiology images, thus reducing dependence on specialist radiologists. By catalyzing early detection and accurate diagnoses, AI-powered diagnostic tools can substantially enhance healthcare outcomes in regions lacking sufficient medical expertise.\\n\\nPersonalized Treatment Plans: Customizing treatment plans to suit individual patient needs is fundamental for optimal healthcare outcomes. However, cultural and socioeconomic hurdles often impede access to personalized treatments in developing regions. AI and machine learning algorithms can dismantle these obstacles by assessing a broad spectrum of patient data, comprising genetic information, socioeconomic parameters, and cultural contexts. By integrating various facets of a patient's life, these algorithms can suggest personalized treatment plans that are effective, suitable, and economically viable. Such an approach ensures that healthcare interventions are accessible and congruent with the local environment, thus improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems: Geographical barriers and inadequate healthcare infrastructure often pose significant difficulties for patients in developing regions.\\\"\",\n",
      "    \"Apologies for the oversight. Here is the corrected version with bolded changes.\\n\\n\\\"In recent years, there has been a significant **increase** in AI-powered solutions **designed** to address unmet medical needs, particularly in resource-limited settings and **emerging regions** like Africa. These advancements hold the potential to greatly **enhance** healthcare outcomes, accessibility, and efficiency. This report will **delve into** the development and application of AI-powered diagnostic tools, personalized treatment plans, and remote monitoring systems, **underlining** the importance of ethical considerations when employing these technologies.\\n\\nAI-Powered Diagnostic Tools: In settings with limited resources, the **key** to effective healthcare intervention lies in early detection and precise diagnoses. AI-powered diagnostic tools are emerging as a promising solution to this challenge. These tools **leverage** machine learning algorithms to **analyze** extensive datasets, thereby enabling healthcare professionals to detect diseases at an earlier stage with **increased** accuracy. For instance, image recognition algorithms have shown significant improvements in identifying diseases from radiology images, thus **reducing dependence** on specialist radiologists. By **catalyzing** early detection and accurate diagnoses, AI-powered diagnostic tools can substantially **enhance** healthcare outcomes in regions **lacking** sufficient medical expertise.\\n\\nPersonalized Treatment Plans: **Customizing** treatment plans to suit individual patient needs is fundamental for optimal healthcare outcomes. However, cultural and socioeconomic **hurdles** often impede access to personalized treatments in developing regions. AI and machine learning algorithms can **dismantle** these obstacles by assessing a broad **spectrum** of patient data, **comprising** genetic information, socioeconomic parameters, and cultural contexts. By **integrating** various facets of a patient's life, these algorithms can suggest personalized treatment plans that are effective, suitable, and economically viable. Such an approach ensures that healthcare interventions are **accessible** and **congruent** with the local environment, thus improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems: **Geographical barriers** and **inadequate** healthcare infrastructure often pose significant difficulties for patients in developing regions.\\\"\"\n",
      "  ],\n",
      "  \"response_b\": [\n",
      "    \"Here's a revised version of the business report with corrections and suggestions for enhancement:\\n\\n\\\"In recent years, there has been a surge in AI-powered solutions aimed at addressing unmet medical needs, particularly in resource-limited settings and developing regions such as Africa. These advancements have the potential to significantly improve healthcare outcomes, accessibility, and efficiency. This section will explore the development and application of AI-powered diagnostic tools, personalized treatment plans, remote monitoring systems, and the importance of ethical considerations in using these technologies.\\n\\nAI-Powered Diagnostic Tools:\\nIn resource-limited settings, early detection and accurate diagnoses are critical for effective healthcare intervention. AI-powered diagnostic tools have emerged as a promising solution, leveraging machine learning algorithms to process large datasets and enable healthcare professionals to detect diseases at earlier stages with higher accuracy rates. For instance, image recognition algorithms have made significant progress in identifying illnesses through radiology images, reducing the reliance on expert radiologists. By facilitating early detection and precise diagnoses, AI-powered diagnostic tools can significantly improve healthcare outcomes in regions with limited medical expertise.\\n\\nPersonalized Treatment Plans:\\nTailoring treatment plans to each patient's needs is essential for optimal healthcare outcomes. However, cultural and socio-economic challenges often hamper access to tailored treatments in developing regions. AI and machine learning algorithms can address these barriers by evaluating a wide range of patient data, including genetic information, socio-economic factors, and cultural context. By considering various aspects of a patient's life, these algorithms can recommend tailored treatment plans that are effective, appropriate, and economically feasible. This approach ensures that healthcare interventions are accessible and compatible with the local context, ultimately improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems:\\nGeographical constraints and limited healthcare infrastructure make it difficult for patients in developing regions to access medical facilities. Remote monitoring systems powered by AI and machine learning can help address this challenge by enabling healthcare professionals to monitor patients remotely. These systems can track vital signs, such as blood pressure and heart rate, and alert healthcare professionals to any changes or potential\",\n",
      "    \"My apologies, here's the revised version with the requested changes in bold:\\n\\n\\\"In recent years, there has been a surge in AI-powered solutions aimed at addressing unmet medical needs, particularly in resource-limited settings and developing regions such as Africa. These advancements have the potential to significantly improve healthcare outcomes, accessibility, and efficiency. This section will explore the development and application of AI-powered diagnostic tools, personalized treatment plans, remote monitoring systems, and the importance of ethical considerations in using these technologies.\\n\\nAI-Powered Diagnostic Tools:\\n\\\\textbf{In resource-limited settings, early detection and accurate diagnoses are critical for effective healthcare intervention.} AI-powered diagnostic tools have emerged as a promising solution, leveraging machine learning algorithms to process large datasets and enable healthcare professionals to detect diseases at earlier stages with higher accuracy rates. For instance, \\\\textbf{image recognition algorithms have made significant progress in identifying illnesses through radiology images}, reducing the reliance on expert radiologists. By facilitating early detection and precise diagnoses, AI-powered diagnostic tools can significantly improve healthcare outcomes in regions with limited medical expertise.\\n\\nPersonalized Treatment Plans:\\n\\\\textbf{Tailoring treatment plans to each patient's needs is essential for optimal healthcare outcomes.} However, cultural and socio-economic challenges often hamper access to tailored treatments in developing regions. AI and machine learning algorithms can address these barriers by evaluating a wide range of patient data, including genetic information, socio-economic factors, and cultural context. By considering various aspects of a patient's life, these algorithms can recommend tailored treatment plans that are effective, appropriate, and economically feasible. This approach ensures that healthcare interventions are accessible and compatible with the local context, ultimately improving patient outcomes in resource-limited settings.\\n\\nRemote Monitoring Systems:\\n\\\\textbf{Geographical constraints and limited healthcare infrastructure make it difficult for patients in developing regions to access medical facilities.} Remote monitoring systems powered by AI and machine learning can help address this challenge by enabling healthcare professionals to monitor patients remotely. These systems can track vital signs, such as blood pressure and heart rate, and\"\n",
      "  ],\n",
      "  \"winner_model_a\": 1,\n",
      "  \"winner_model_b\": 0,\n",
      "  \"winner_tie\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# grab the column as a plain Python list of strings\n",
    "col = train_dataset[\"train\"][\"response_a\"]\n",
    "\n",
    "# find the first row with multiple items\n",
    "first_multi = next(\n",
    "    (\n",
    "        (i, arr)\n",
    "        for i, raw in enumerate(col)\n",
    "        for arr in [json.loads(raw)]\n",
    "        if isinstance(arr, list) and len(arr) > 1\n",
    "    ),\n",
    "    None\n",
    ")\n",
    "\n",
    "if first_multi:\n",
    "    i, arr = first_multi\n",
    "    print(f\"First row with >1 element: row {i}: {arr}\")\n",
    "\n",
    "    # now pretty-print the full row at index i\n",
    "    row = train_dataset[\"train\"][i].copy()\n",
    "\n",
    "    # parse the JSON-encoded fields\n",
    "    row[\"prompt\"]     = json.loads(row[\"prompt\"])\n",
    "    row[\"response_a\"] = arr\n",
    "    row[\"response_b\"] = json.loads(row[\"response_b\"])\n",
    "\n",
    "    print(\"\\nRow detail:\")\n",
    "    print(json.dumps(row, indent=2))\n",
    "else:\n",
    "    print(\"No rows with >1 element found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab06fca",
   "metadata": {
    "papermill": {
     "duration": 0.049892,
     "end_time": "2025-06-20T00:52:34.089733",
     "exception": false,
     "start_time": "2025-06-20T00:52:34.039841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Now i want to format the input training data to be an input to the model.\n",
    "\n",
    "Note that there can be multi-turn conversations.\n",
    "This will be a text input with the following format:\n",
    "\n",
    "```text\n",
    "## Turn 1\n",
    "### Prompt\n",
    "<prompt[0]>\n",
    "\n",
    "### Response A\n",
    "<response_a[0]>\n",
    "\n",
    "### Response B\n",
    "<response_b[0]>\n",
    "\n",
    "## Turn 2\n",
    "### Prompt\n",
    "<prompt[1]>\n",
    "\n",
    "### Response A\n",
    "<response_a[1]>\n",
    "\n",
    "### Response B\n",
    "<response_b[1]>\n",
    "\n",
    "---\n",
    "\n",
    "Which is better?\n",
    "Answer:\n",
    "```\n",
    "\n",
    "Where `<label>` is one of `a`, `b`, or `tie`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3ec00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:34.188362Z",
     "iopub.status.busy": "2025-06-20T00:52:34.188114Z",
     "iopub.status.idle": "2025-06-20T00:52:34.212592Z",
     "shell.execute_reply": "2025-06-20T00:52:34.211568Z"
    },
    "papermill": {
     "duration": 0.075556,
     "end_time": "2025-06-20T00:52:34.213668",
     "exception": false,
     "start_time": "2025-06-20T00:52:34.138112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Preprocessed example:\n",
      "Input length: 1024\n",
      "Labels length: 1024\n",
      "Lengths match: True\n",
      "\n",
      "Input IDs:\n",
      "---------------------\n",
      "## Turn 1\n",
      "### Prompt\n",
      "Does influenza a and b have different seasonality? \n",
      "\n",
      "### Response A\n",
      "Yes, Influenza A and Influenza B, which are two types of influenza viruses, can exhibit different seasonal patterns. In general, both viruses tend to peak during winter in the Northern and Southern Hemispheres, as colder temperatures and dryer air promote their transmission. However, subtle differences in their seasonality have been observed in certain regions.\n",
      "\n",
      "Influenza A can circulate throughout the year but tends to peak from late fall through early spring. This type of influenza can cause more severe outbreaks and pandemics due to its genetic variability, and it can infect both humans and animals.\n",
      "\n",
      "Influenza B, on the other hand, usually peaks later in the year than Influenza A, often during the spring. Its epidemics are typically less severe than those caused by Influenza A, and it mainly infects humans.\n",
      "\n",
      "It is important to note that seasonality can vary from year to year and can be influenced by factors such as vaccination rates, herd immunity, and the specific strains of the virus circulating each season.\n",
      "\n",
      "### Response B\n",
      "Influenza A and B are both respiratory viruses that cause seasonal epidemics of disease, known as the flu season, which occurs in the colder months in each hemisphere. While both types can cause seasonal flu epidemics, their patterns can differ somewhat in terms of timing and impact.\n",
      "\n",
      "Influenza A viruses are typically the main cause of larger seasonal flu epidemics. They can be found in many different animals, including ducks, chickens, pigs, whales, humans, and other mammals. Influenza A viruses are divided into subtypes based on two proteins on the surface of the virus: hemagglutinin (H) and neuraminidase (N). The subtypes that commonly circulate in humans are A(H1N1) and A(H3N2).\n",
      "\n",
      "Influenza B viruses circulate widely only among humans. There are two lineages of influenza B viruses: B/Yamagata and B/Victoria. Unlike influenza A viruses, influenza B viruses are not classified by subtypes. Influenza B is usually less common than influenza A during most flu seasons, though it can be the dominant strain in some seasons.\n",
      "\n",
      "While influenza A typically has a more pronounced peak and can cause more severe epidemics, influenza B can also contribute to the seasonal illness burden. Sometimes influenza B can cause outbreaks later in the flu season after the initial influenza A wave. However, the timing can vary and is not the same every year. The seasonality of both influenza A and B can be influenced by factors such as the specific strains circulating, population immunity, and environmental conditions.\n",
      "\n",
      "Vaccines are formulated annually to protect against both influenza A and B, typically containing two A strains (H1N1 and H3N2) and one or two B strains (one from each lineage). It's important to get vaccinated every year as the strains included in the vaccine may change based on predictions for the upcoming flu season.\n",
      "\n",
      "\n",
      "Which is better?\n",
      "Answer: b<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "---------------------\n",
      "Decoded Labels:\n",
      "b\n",
      "\n",
      "First non-ignore label at position: 621\n",
      "Context around label start: ?\n",
      "Answer: b<|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(\n",
    "    examples,\n",
    "    tokenizer,\n",
    "    max_length: int = 1024,  # Increased from 512 for multi-turn conversations\n",
    "):\n",
    "    \"\"\"\n",
    "    More efficient preprocessing with better label alignment and proper padding.\n",
    "    \"\"\"\n",
    "    # 1) Build the text inputs in the desired format\n",
    "    inputs = []\n",
    "    for prompt_json, response_a_json, response_b_json in zip(\n",
    "        examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"]\n",
    "    ):\n",
    "        # JSON decode the columns to handle multi-turn conversations\n",
    "        prompts = json.loads(prompt_json)\n",
    "        responses_a = json.loads(response_a_json)\n",
    "        responses_b = json.loads(response_b_json)\n",
    "        \n",
    "        # Build conversation with turn-by-turn format\n",
    "        conversation_parts = []\n",
    "        for i, (prompt_turn, response_a_turn, response_b_turn) in enumerate(zip(prompts, responses_a, responses_b), 1):\n",
    "            turn_text = f\"## Turn {i}\\n\"\n",
    "            turn_text += \"### Prompt\\n\"\n",
    "            turn_text += f\"{prompt_turn}\\n\\n\"\n",
    "\n",
    "            turn_text += \"### Response A\\n\"\n",
    "            turn_text += f\"{response_a_turn}\\n\\n\"\n",
    "\n",
    "            turn_text += \"### Response B\\n\"\n",
    "            turn_text += f\"{response_b_turn}\\n\"\n",
    "\n",
    "            conversation_parts.append(turn_text)\n",
    "        \n",
    "        # Join all turns with separator and add final question\n",
    "        conversation = \"\\n---\\n\\n\".join(conversation_parts)\n",
    "        input_text = f\"{conversation}\\n\\nWhich is better?\\nAnswer: \"  # Added space after colon\n",
    "        inputs.append(input_text)\n",
    "\n",
    "    # 2) Build the target responses\n",
    "    targets = []\n",
    "    for wa, wb, wt in zip(\n",
    "        examples[\"winner_model_a\"],\n",
    "        examples[\"winner_model_b\"],\n",
    "        examples[\"winner_tie\"],\n",
    "    ):\n",
    "        if wa == 1:\n",
    "            targets.append(\"a\")\n",
    "        elif wb == 1:\n",
    "            targets.append(\"b\")\n",
    "        elif wt == 1:\n",
    "            targets.append(\"tie\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid winner values: must be one of a, b, or tie.\")\n",
    "\n",
    "    # 3) More efficient tokenization - separate input and target tokenization\n",
    "    # Tokenize inputs first with no padding to get raw lengths\n",
    "    input_tokens = tokenizer(inputs, add_special_tokens=True, padding=False, truncation=False)\n",
    "    target_tokens = tokenizer(targets, add_special_tokens=False, padding=False, truncation=False)\n",
    "    \n",
    "    # 4) Combine and create labels more reliably with proper padding\n",
    "    model_inputs = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "    \n",
    "    for i, (inp_ids, tgt_ids) in enumerate(zip(input_tokens[\"input_ids\"], target_tokens[\"input_ids\"])):\n",
    "        # Combine input + target\n",
    "        combined_ids = inp_ids + tgt_ids\n",
    "        \n",
    "        # Truncate if needed - prioritize keeping the full target\n",
    "        if len(combined_ids) > max_length:\n",
    "            target_len = len(tgt_ids)\n",
    "            if target_len < max_length:  # Only truncate if we can fit the target\n",
    "                input_truncated = combined_ids[:max_length - target_len]\n",
    "                combined_ids = input_truncated + tgt_ids\n",
    "            else:\n",
    "                # If target itself is too long, truncate everything\n",
    "                combined_ids = combined_ids[:max_length]\n",
    "        \n",
    "        # Create labels: -100 for input part, actual tokens for target part\n",
    "        input_len = len(inp_ids) if len(combined_ids) > len(inp_ids) else len(combined_ids) - len(tgt_ids)\n",
    "        input_len = max(0, input_len)  # Ensure non-negative\n",
    "        \n",
    "        labels = [-100] * input_len + combined_ids[input_len:]\n",
    "        \n",
    "        # Ensure labels match combined_ids length\n",
    "        if len(labels) != len(combined_ids):\n",
    "            labels = labels[:len(combined_ids)]\n",
    "        \n",
    "        # Pad sequences to max_length for consistent batching\n",
    "        # Pad input_ids and attention_mask\n",
    "        attention_mask = [1] * len(combined_ids)\n",
    "        \n",
    "        if len(combined_ids) < max_length:\n",
    "            padding_length = max_length - len(combined_ids)\n",
    "            combined_ids += [tokenizer.pad_token_id] * padding_length\n",
    "            attention_mask += [0] * padding_length\n",
    "            labels += [-100] * padding_length\n",
    "        \n",
    "        model_inputs[\"input_ids\"].append(combined_ids)\n",
    "        model_inputs[\"labels\"].append(labels)\n",
    "        model_inputs[\"attention_mask\"].append(attention_mask)\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "# Test preprocessing on the first row as an example\n",
    "example = train_dataset[\"train\"].select(range(1))\n",
    "example_preprocessed = preprocess_function(\n",
    "    example,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Improved Preprocessed example:\")\n",
    "print(\"Input length:\", len(example_preprocessed[\"input_ids\"][0]))\n",
    "print(\"Labels length:\", len(example_preprocessed[\"labels\"][0]))\n",
    "print(\"Lengths match:\", len(example_preprocessed[\"input_ids\"][0]) == len(example_preprocessed[\"labels\"][0]))\n",
    "\n",
    "print(\"\\nInput IDs:\")\n",
    "print(\"---------------------\")\n",
    "print(tokenizer.decode(example_preprocessed[\"input_ids\"][0]))\n",
    "\n",
    "# Remove -100 from labels for display\n",
    "labels = [token_id for token_id in example_preprocessed[\"labels\"][0] if token_id != -100]\n",
    "print(\"---------------------\")\n",
    "print(\"Decoded Labels:\")\n",
    "print(tokenizer.decode(labels))\n",
    "\n",
    "# Show where labels start\n",
    "labels_full = example_preprocessed[\"labels\"][0]\n",
    "first_non_ignore = next((i for i, x in enumerate(labels_full) if x != -100), None)\n",
    "print(f\"\\nFirst non-ignore label at position: {first_non_ignore}\")\n",
    "if first_non_ignore and first_non_ignore > 5:\n",
    "    context_start = max(0, first_non_ignore - 5)\n",
    "    context_end = min(len(example_preprocessed[\"input_ids\"][0]), first_non_ignore + 5)\n",
    "    print(f\"Context around label start: {tokenizer.decode(example_preprocessed['input_ids'][0][context_start:context_end])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98561a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:52:34.313384Z",
     "iopub.status.busy": "2025-06-20T00:52:34.312767Z",
     "iopub.status.idle": "2025-06-20T00:53:54.960160Z",
     "shell.execute_reply": "2025-06-20T00:53:54.959550Z"
    },
    "papermill": {
     "duration": 80.698657,
     "end_time": "2025-06-20T00:53:54.961834",
     "exception": false,
     "start_time": "2025-06-20T00:52:34.263177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3990f79c1a3402fa16130dced2ccf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51729 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9036 > 8192). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5608cc140a75457ba22b6752cccec2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = train_dataset.map(\n",
    "    lambda ex: preprocess_function(ex, tokenizer),\n",
    "    batched=True,\n",
    "    # optionally drop old columns\n",
    "    remove_columns=train_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4d7525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:55.064405Z",
     "iopub.status.busy": "2025-06-20T00:53:55.063546Z",
     "iopub.status.idle": "2025-06-20T00:53:55.074505Z",
     "shell.execute_reply": "2025-06-20T00:53:55.073648Z"
    },
    "papermill": {
     "duration": 0.063872,
     "end_time": "2025-06-20T00:53:55.075589",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.011717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example rows from the tokenized dataset:\n",
      "--- input_ids ---\n",
      "## Turn 1\n",
      "### Prompt\n",
      "Does influenza a and b have different seasonality? \n",
      "\n",
      "### Response A\n",
      "Yes, Influenza A and Influenza B, which are two types of influenza viruses, can exhibit different seasonal patterns. In general, both viruses tend to peak during winter in the Northern and Southern Hemispheres, as colder temperatures and dryer air promote their transmission. However, subtle differences in their seasonality have been observed in certain regions.\n",
      "\n",
      "Influenza A can circulate throughout the year but tends to peak from late fall through early spring. This type of influenza can cause more severe outbreaks and pandemics due to its genetic variability, and it can infect both humans and animals.\n",
      "\n",
      "Influenza B, on the other hand, usually peaks later in the year than Influenza A, often during the spring. Its epidemics are typically less severe than those caused by Influenza A, and it mainly infects humans.\n",
      "\n",
      "It is important to note that seasonality can vary from year to year and can be influenced by factors such as vaccination rates, herd immunity, and the specific strains of the virus circulating each season.\n",
      "\n",
      "### Response B\n",
      "Influenza A and B are both respiratory viruses that cause seasonal epidemics of disease, known as the flu season, which occurs in the colder months in each hemisphere. While both types can cause seasonal flu epidemics, their patterns can differ somewhat in terms of timing and impact.\n",
      "\n",
      "Influenza A viruses are typically the main cause of larger seasonal flu epidemics. They can be found in many different animals, including ducks, chickens, pigs, whales, humans, and other mammals. Influenza A viruses are divided into subtypes based on two proteins on the surface of the virus: hemagglutinin (H) and neuraminidase (N). The subtypes that commonly circulate in humans are A(H1N1) and A(H3N2).\n",
      "\n",
      "Influenza B viruses circulate widely only among humans. There are two lineages of influenza B viruses: B/Yamagata and B/Victoria. Unlike influenza A viruses, influenza B viruses are not classified by subtypes. Influenza B is usually less common than influenza A during most flu seasons, though it can be the dominant strain in some seasons.\n",
      "\n",
      "While influenza A typically has a more pronounced peak and can cause more severe epidemics, influenza B can also contribute to the seasonal illness burden. Sometimes influenza B can cause outbreaks later in the flu season after the initial influenza A wave. However, the timing can vary and is not the same every year. The seasonality of both influenza A and B can be influenced by factors such as the specific strains circulating, population immunity, and environmental conditions.\n",
      "\n",
      "Vaccines are formulated annually to protect against both influenza A and B, typically containing two A strains (H1N1 and H3N2) and one or two B strains (one from each lineage). It's important to get vaccinated every year as the strains included in the vaccine may change based on predictions for the upcoming flu season.\n",
      "\n",
      "\n",
      "Which is better?\n",
      "Answer: b\n",
      "---- labels -----\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "# Let's check the first 2 rows of the tokenized dataset\n",
    "\n",
    "print(\"Example rows from the tokenized dataset:\")\n",
    "print(\"--- input_ids ---\")\n",
    "print(tokenizer.decode(tokenized[\"train\"][0][\"input_ids\"], skip_special_tokens=True))\n",
    "print(\"---- labels -----\")\n",
    "\n",
    "# Clear the -100 padding from labels for display\n",
    "labels = [token_id for token_id in tokenized[\"train\"][0][\"labels\"] if token_id != -100]\n",
    "print(tokenizer.decode(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad8564",
   "metadata": {
    "papermill": {
     "duration": 0.048644,
     "end_time": "2025-06-20T00:53:55.173687",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.125043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Now what\n",
    "\n",
    "Now we have a dataset in the right format with both the inputs and the labels,\n",
    "we can now train wowowow\n",
    "\n",
    "Let's use the `peft` library to try prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1bea000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:55.275800Z",
     "iopub.status.busy": "2025-06-20T00:53:55.275157Z",
     "iopub.status.idle": "2025-06-20T00:53:55.347303Z",
     "shell.execute_reply": "2025-06-20T00:53:55.346295Z"
    },
    "papermill": {
     "duration": 0.123377,
     "end_time": "2025-06-20T00:53:55.348460",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.225083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 51729\n",
      "Evaluation dataset size: 5748\n",
      "\n",
      "Checking sequence lengths consistency:\n",
      "First sample length: 1024\n",
      "Sample 0: input_ids=1024, labels=1024, attention_mask=1024\n",
      "Sample 1: input_ids=1024, labels=1024, attention_mask=1024\n",
      "Sample 2: input_ids=1024, labels=1024, attention_mask=1024\n",
      "Sample 3: input_ids=1024, labels=1024, attention_mask=1024\n",
      "Sample 4: input_ids=1024, labels=1024, attention_mask=1024\n",
      "All samples have consistent lengths!\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# Use the tokenized datasets directly with the Trainer\n",
    "train_ds = tokenized[\"train\"]\n",
    "eval_ds = tokenized[\"test\"]\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Evaluation dataset size: {len(eval_ds)}\")\n",
    "\n",
    "# Check that all sequences are now the same length\n",
    "print(f\"\\nChecking sequence lengths consistency:\")\n",
    "first_sample_length = len(train_ds[0][\"input_ids\"])\n",
    "print(f\"First sample length: {first_sample_length}\")\n",
    "\n",
    "# Check a few more samples to ensure consistency\n",
    "for i in range(min(5, len(train_ds))):\n",
    "    length = len(train_ds[i][\"input_ids\"])\n",
    "    labels_length = len(train_ds[i][\"labels\"])\n",
    "    attention_length = len(train_ds[i][\"attention_mask\"])\n",
    "    print(f\"Sample {i}: input_ids={length}, labels={labels_length}, attention_mask={attention_length}\")\n",
    "    \n",
    "    if length != labels_length or length != attention_length:\n",
    "        print(f\"WARNING: Length mismatch in sample {i}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All samples have consistent lengths!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a11957",
   "metadata": {
    "papermill": {
     "duration": 0.04967,
     "end_time": "2025-06-20T00:53:55.447732",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.398062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PEFT Config\n",
    "\n",
    "We use p-tuning instead of prefix tuning or prompt tuning.\n",
    "\n",
    "### Why?\n",
    "Prefix Tuning is more suitable for generation, while we're doing classification\n",
    "\n",
    "Prompt tuning is very parameter efficient (e.g. could only need to train 8-16 embeddings) but can underperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa090d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:55.549003Z",
     "iopub.status.busy": "2025-06-20T00:53:55.548678Z",
     "iopub.status.idle": "2025-06-20T00:53:55.866427Z",
     "shell.execute_reply": "2025-06-20T00:53:55.865611Z"
    },
    "papermill": {
     "duration": 0.370007,
     "end_time": "2025-06-20T00:53:55.867656",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.497649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 390,336 || all params: 134,905,344 || trainable%: 0.2893\n"
     ]
    }
   ],
   "source": [
    "from peft import PromptEncoderConfig, get_peft_model\n",
    "\n",
    "# Improved PEFT configuration with more capacity and regularization\n",
    "peft_config = PromptEncoderConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    num_virtual_tokens=50,\n",
    "    encoder_hidden_size=256,\n",
    "    encoder_dropout=0.1,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b399f69",
   "metadata": {
    "papermill": {
     "duration": 0.050523,
     "end_time": "2025-06-20T00:53:55.968311",
     "exception": false,
     "start_time": "2025-06-20T00:53:55.917788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "Setup optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed7e2204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:56.071881Z",
     "iopub.status.busy": "2025-06-20T00:53:56.071565Z",
     "iopub.status.idle": "2025-06-20T00:53:58.033207Z",
     "shell.execute_reply": "2025-06-20T00:53:58.032473Z"
    },
    "papermill": {
     "duration": 2.016324,
     "end_time": "2025-06-20T00:53:58.034947",
     "exception": false,
     "start_time": "2025-06-20T00:53:56.018623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1372867196.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "import torch\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Since we're already padding in preprocessing, use a simpler data collator\n",
    "# that doesn't try to pad again\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're doing causal LM, not masked LM\n",
    "    pad_to_multiple_of=None,  # Don't pad again since we already padded in preprocessing\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Improved training arguments with better optimization and scheduling\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llm-classification-ft-peft-p-tuning/output\",\n",
    "    learning_rate=3e-4,              # More conservative learning rate for fine-tuning\n",
    "\n",
    "    # Smaller batch sizes for memory efficiency\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,    # Keep eval batch size higher\n",
    "\n",
    "    # Increase gradient accumulation to maintain effective batch size\n",
    "    gradient_accumulation_steps=16,  # Effective batch size = 2 * 16 = 32\n",
    "    # num_train_epochs=0.01,              # More epochs for better convergence\n",
    "    max_steps=10, # TEMP: For testing without training too long\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Better optimization settings\n",
    "    warmup_ratio=0.1,                # Warmup for training stability\n",
    "    lr_scheduler_type=\"cosine\",      # Cosine annealing instead of linear\n",
    "    \n",
    "    # Better evaluation and saving strategy\n",
    "    eval_strategy=\"steps\",           # Evaluate more frequently\n",
    "    eval_steps=100,                  # Evaluate every 100 steps\n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100,                  # Save every 100 steps\n",
    "    save_total_limit=2,              # Limit checkpoints to save disk space\n",
    "\n",
    "    # Early stopping and best model selection\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Logging and reporting\n",
    "    report_to=\"wandb\" if not ON_KAGGLE else None,\n",
    "    run_name=\"llm-classification-ft-peft-p-tuning-improved\",\n",
    "    logging_steps=10,                # More frequent logging\n",
    "\n",
    "    # Memory optimization settings\n",
    "    dataloader_pin_memory=False,     # Disable pin memory to save GPU memory\n",
    "    dataloader_num_workers=0,        # Avoid multiprocessing overhead\n",
    "    gradient_checkpointing=True,     # Trade compute for memory\n",
    "    fp16=True,                       # Use half precision to reduce memory usage\n",
    "\n",
    "    # Additional optimizations\n",
    "    remove_unused_columns=False,     # Important for custom preprocessing\n",
    "    label_names=[\"labels\"],          # Fix for PEFT model warning\n",
    "    torch_empty_cache_steps=50,      # Clear cache periodically\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2fb8d",
   "metadata": {
    "papermill": {
     "duration": 0.049837,
     "end_time": "2025-06-20T00:53:58.146350",
     "exception": false,
     "start_time": "2025-06-20T00:53:58.096513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Now actually train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca5c34d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:58.250581Z",
     "iopub.status.busy": "2025-06-20T00:53:58.249784Z",
     "iopub.status.idle": "2025-06-20T00:53:58.258910Z",
     "shell.execute_reply": "2025-06-20T00:53:58.258182Z"
    },
    "papermill": {
     "duration": 0.063021,
     "end_time": "2025-06-20T00:53:58.260074",
     "exception": false,
     "start_time": "2025-06-20T00:53:58.197053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE training:\n",
      "GPU Memory Usage:\n",
      "  Allocated: 0.52 GB\n",
      "  Reserved:  0.53 GB\n",
      "  Total:     14.74 GB\n",
      "  Free:      14.21 GB\n",
      "  Usage:     3.5%\n",
      "\n",
      "After clearing cache:\n",
      "GPU Memory Usage:\n",
      "  Allocated: 0.52 GB\n",
      "  Reserved:  0.53 GB\n",
      "  Total:     14.74 GB\n",
      "  Free:      14.21 GB\n",
      "  Usage:     3.5%\n"
     ]
    }
   ],
   "source": [
    "# Print current GPU memory usage\n",
    "import torch\n",
    "\n",
    "def print_gpu_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3  # Convert to GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        \n",
    "        print(\"GPU Memory Usage:\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} GB\") \n",
    "        print(f\"  Total:     {total:.2f} GB\")\n",
    "        print(f\"  Free:      {total - reserved:.2f} GB\")\n",
    "        print(f\"  Usage:     {allocated/total*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "print(\"BEFORE training:\")\n",
    "print_gpu_memory_usage()\n",
    "\n",
    "# Clear any cached memory\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nAfter clearing cache:\")\n",
    "print_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362da82c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:58.367943Z",
     "iopub.status.busy": "2025-06-20T00:53:58.367161Z",
     "iopub.status.idle": "2025-06-20T00:53:58.843159Z",
     "shell.execute_reply": "2025-06-20T00:53:58.842433Z"
    },
    "papermill": {
     "duration": 0.528059,
     "end_time": "2025-06-20T00:53:58.844344",
     "exception": false,
     "start_time": "2025-06-20T00:53:58.316285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training memory optimization complete\n",
      "GPU Memory Usage:\n",
      "  Allocated: 0.52 GB\n",
      "  Reserved:  0.53 GB\n",
      "  Total:     14.74 GB\n",
      "  Free:      14.21 GB\n",
      "  Usage:     3.5%\n",
      "\n",
      "Model memory footprint: 0.50 GB\n",
      "trainable params: 390,336 || all params: 134,905,344 || trainable%: 0.2893\n"
     ]
    }
   ],
   "source": [
    "# Memory optimization before training\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Clear Python garbage collector\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set PYTORCH environment variable for memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "print(\"Pre-training memory optimization complete\")\n",
    "print_gpu_memory_usage()\n",
    "\n",
    "# Check model's memory footprint\n",
    "print(f\"\\nModel memory footprint: {model.get_memory_footprint() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Print trainable parameters info\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c043619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:53:58.946586Z",
     "iopub.status.busy": "2025-06-20T00:53:58.946104Z",
     "iopub.status.idle": "2025-06-20T00:56:43.487094Z",
     "shell.execute_reply": "2025-06-20T00:56:43.486432Z"
    },
    "papermill": {
     "duration": 164.593189,
     "end_time": "2025-06-20T00:56:43.488296",
     "exception": false,
     "start_time": "2025-06-20T00:53:58.895107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250620_005359-5sq62ljg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllm-classification-ft-peft-p-tuning-improved\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft/runs/5sq62ljg\u001b[0m\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 02:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-10)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.9452970504760743, metrics={'train_runtime': 163.7051, 'train_samples_per_second': 3.909, 'train_steps_per_second': 0.061, 'total_flos': 417608981544960.0, 'train_loss': 0.9452970504760743, 'epoch': 0.012371452872496714})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d35237c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:56:43.596202Z",
     "iopub.status.busy": "2025-06-20T00:56:43.595918Z",
     "iopub.status.idle": "2025-06-20T00:56:46.246802Z",
     "shell.execute_reply": "2025-06-20T00:56:46.246249Z"
    },
    "papermill": {
     "duration": 2.705437,
     "end_time": "2025-06-20T00:56:46.247907",
     "exception": false,
     "start_time": "2025-06-20T00:56:43.542470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact model-llm-classification-ft-peft-p-tuning-improved; uploading artifact model-llm-classification-ft-peft-p-tuning-improved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact model-llm-classification-ft-peft-p-tuning-improved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch ▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/global_step ▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/learning_rate ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 417608981544960.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 0.01237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 19003.60547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.9453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.9453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 163.7051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 3.909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 0.061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mllm-classification-ft-peft-p-tuning-improved\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft/runs/5sq62ljg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250620_005359-5sq62ljg/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb18fce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T00:56:46.356393Z",
     "iopub.status.busy": "2025-06-20T00:56:46.355637Z",
     "iopub.status.idle": "2025-06-20T00:56:46.510833Z",
     "shell.execute_reply": "2025-06-20T00:56:46.510252Z"
    },
    "papermill": {
     "duration": 0.210715,
     "end_time": "2025-06-20T00:56:46.512202",
     "exception": false,
     "start_time": "2025-06-20T00:56:46.301487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "output_path = \"/kaggle/working/model-output\" if ON_KAGGLE else \"./model-ouput\"\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eafaf3",
   "metadata": {
    "papermill": {
     "duration": 0.052304,
     "end_time": "2025-06-20T00:56:46.618401",
     "exception": false,
     "start_time": "2025-06-20T00:56:46.566097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference Time\n",
    "\n",
    "Now we have a fine tuned model, we can use it to make predictions on the test\n",
    "set to see how well (or more likely how poorly) it does.\n",
    "\n",
    "This is done in the next notebook that uses this one as an input!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 507.586822,
   "end_time": "2025-06-20T00:56:50.137101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T00:48:22.550279",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03e36ce62d2c48b2b7067c3b5723ae28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06d47d0256a7445789e6e7b325b8d10d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_763e430fca6e4043870b6a4d971e8216",
       "placeholder": "​",
       "style": "IPY_MODEL_8a256a3fc414408aa700e2f25feb9411",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 17.9MB/s]"
      }
     },
     "06d8b6a86cf748d8ad0c43f67c80ea01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0d3b61b8590644fe910702eb8973ac48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0fdb9a6d8c9742d6b969b3d4dcda6104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_156639d78af14ac18ce2032c7291c055",
       "placeholder": "​",
       "style": "IPY_MODEL_16380c01fb8f48758a9c8e1e4f401bb7",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json: 100%"
      }
     },
     "0fe06f5d82a84044afac0bca69a1ec8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12bd54a3999641f89016cad6b39d0dfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c34d67751f4f4062aa10029713d15e13",
       "max": 2104556.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ecfe5418865440bd989366a5bc01fe3d",
       "tabbable": null,
       "tooltip": null,
       "value": 2104556.0
      }
     },
     "13d6e1760f614145bcd4a3700fdf52fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_82ffc206d83341cc94a357dfc3739f7e",
       "placeholder": "​",
       "style": "IPY_MODEL_199ce94edacb4bf38194b711021e21fc",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "13deca262c4942909c486fed9e1afdf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "156639d78af14ac18ce2032c7291c055": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16380c01fb8f48758a9c8e1e4f401bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1949176a6ab64289a9f45292c12429f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "199ce94edacb4bf38194b711021e21fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1a5a2b1b5acf4276b6d3f67654669635": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0fdb9a6d8c9742d6b969b3d4dcda6104",
        "IPY_MODEL_30fb6c13141043e58a88db509b60c148",
        "IPY_MODEL_6d02ad23d113466e9ca54f8e6f5364cf"
       ],
       "layout": "IPY_MODEL_a6262271f6a541aba0063d76920da328",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1b5d7eb25473433ca215d29a12d3a92a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2171717e2edb4f319d64b9651058126c",
       "placeholder": "​",
       "style": "IPY_MODEL_44b29b78ec39473f8e0e556b1d87b199",
       "tabbable": null,
       "tooltip": null,
       "value": " 5748/5748 [00:07&lt;00:00, 728.20 examples/s]"
      }
     },
     "20dc43f7259a4d8e944ac6f5b0c455e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21b0dfa6019f4604841e19c924c7ca18",
       "placeholder": "​",
       "style": "IPY_MODEL_65a55dfb49ae473da2220ff25a108e53",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "2171717e2edb4f319d64b9651058126c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21b0dfa6019f4604841e19c924c7ca18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2249484beec74452bb1bab9e5219dee8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b302b77e484047a10cd4f6bd4efad4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0adb909f03642b88c24d9f16e72171a",
       "placeholder": "​",
       "style": "IPY_MODEL_c028e70f16d3482eb6bc32c21e7a0ef9",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: 100%"
      }
     },
     "2c773eb290c74be08787038a91b50922": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f38061edd63436ea7bc812de6a7dcf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_55f87db478904817986f9ced002cd318",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d7d6003273214e7889b3f04b68ab77f9",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "30fb6c13141043e58a88db509b60c148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3db39ae755c0474bbaa2cf862570cef8",
       "max": 111.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_529f1110ec634b949eea1e940fb9222d",
       "tabbable": null,
       "tooltip": null,
       "value": 111.0
      }
     },
     "34aa2b0b477d40649db87b28fc217fc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e05cb9de452d455d9d4cc9fe64a65e29",
       "placeholder": "​",
       "style": "IPY_MODEL_a4c3561901aa4404b5ef72647d6f8475",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.10M/2.10M [00:00&lt;00:00, 24.5MB/s]"
      }
     },
     "36c1438ff5b146d68b55ea24b924e4b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37cebfb2635940e08a621d40069536a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_23b302b77e484047a10cd4f6bd4efad4",
        "IPY_MODEL_632404e03000470d99bc1733cb343ffd",
        "IPY_MODEL_a60b9ec57e9d457aa73320b4eb210ad1"
       ],
       "layout": "IPY_MODEL_67fb329495f84bb88f6d314df9f376b6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "37f45fdda4354266901d4c4c2d34d8f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2249484beec74452bb1bab9e5219dee8",
       "placeholder": "​",
       "style": "IPY_MODEL_f8d543dfe278417e81925c8e6ec8a2f3",
       "tabbable": null,
       "tooltip": null,
       "value": " 704/704 [00:00&lt;00:00, 94.4kB/s]"
      }
     },
     "385a7473825942fbab924a61a8a3641f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3963bad3778746c6b9cbd0747c17bd90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b01b84822684a83ada5020aee8105d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3db39ae755c0474bbaa2cf862570cef8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40e9b63b99b747d99cc04e576b076c5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_748e9f66d8724d82a187baf02ff3b7f6",
       "placeholder": "​",
       "style": "IPY_MODEL_90af33c094ea407686af7b92b751ba89",
       "tabbable": null,
       "tooltip": null,
       "value": " 3.66k/3.66k [00:00&lt;00:00, 425kB/s]"
      }
     },
     "44b29b78ec39473f8e0e556b1d87b199": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "455c2e1883d94fe7a651826f6036c280": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4598941ff56d41aab2c7ca2b4e2e6461": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4aa900b79a774c08aca8b9f27eceb210": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b48638c8254344e186ef1d8ebb027bb4",
       "placeholder": "​",
       "style": "IPY_MODEL_db1cee6d63534659b42ba175a6b300aa",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "511a2407d9204687ab75e3c7f87b4190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b181ae1a3c844534b8bef120d21706c9",
        "IPY_MODEL_2f38061edd63436ea7bc812de6a7dcf2",
        "IPY_MODEL_37f45fdda4354266901d4c4c2d34d8f0"
       ],
       "layout": "IPY_MODEL_385a7473825942fbab924a61a8a3641f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "529f1110ec634b949eea1e940fb9222d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "55f87db478904817986f9ced002cd318": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5608cc140a75457ba22b6752cccec2b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_13d6e1760f614145bcd4a3700fdf52fa",
        "IPY_MODEL_f81a74fe5ec74397a3970911d1363bb5",
        "IPY_MODEL_1b5d7eb25473433ca215d29a12d3a92a"
       ],
       "layout": "IPY_MODEL_5df8a4b7fa274c1cbd168021fb387e17",
       "tabbable": null,
       "tooltip": null
      }
     },
     "58eb1ba3b2f14e6c8713cd705311012b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_89e4c3b290e24a639cae1b10aef37801",
        "IPY_MODEL_12bd54a3999641f89016cad6b39d0dfc",
        "IPY_MODEL_34aa2b0b477d40649db87b28fc217fc0"
       ],
       "layout": "IPY_MODEL_91720b31bbf54915adfa9152ef56c5c9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5aae5acc4d3a418b8b6466107419dd76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5cb56de621ac4ada950264a862f716b5",
        "IPY_MODEL_ee8e740a973f4ccba40b9361a2ae9a8f",
        "IPY_MODEL_8131e2065cee429698b20733518f5201"
       ],
       "layout": "IPY_MODEL_2c773eb290c74be08787038a91b50922",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5b89020b20094b65943b670637569a38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cb56de621ac4ada950264a862f716b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b92377343f7403e86b7457d5d6a2455",
       "placeholder": "​",
       "style": "IPY_MODEL_ab13cc30022340539c854085e9d63862",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "5df8a4b7fa274c1cbd168021fb387e17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fb5678cd84448d9b8fab4aacab58b2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "632404e03000470d99bc1733cb343ffd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c60c48178bd74a20be2e10be50eff9d3",
       "max": 800662.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_06d8b6a86cf748d8ad0c43f67c80ea01",
       "tabbable": null,
       "tooltip": null,
       "value": 800662.0
      }
     },
     "6389772bc68e4735b21c7528324443d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63e7cef133804e3cbff17482692015f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65a55dfb49ae473da2220ff25a108e53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6621ad743e9b48888569f34c6e8215c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13deca262c4942909c486fed9e1afdf6",
       "max": 466391.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_938f6fe171424cb7b14fbe16423420e0",
       "tabbable": null,
       "tooltip": null,
       "value": 466391.0
      }
     },
     "67fb329495f84bb88f6d314df9f376b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d02ad23d113466e9ca54f8e6f5364cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c03917cc38cc4ffda6a05a0a5013244f",
       "placeholder": "​",
       "style": "IPY_MODEL_1949176a6ab64289a9f45292c12429f9",
       "tabbable": null,
       "tooltip": null,
       "value": " 111/111 [00:00&lt;00:00, 14.2kB/s]"
      }
     },
     "748e9f66d8724d82a187baf02ff3b7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "750fbd98661c4bff9d028e6dc4c44bf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "763e430fca6e4043870b6a4d971e8216": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77f8a09c25024407bc9b3e32001d01c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78615c7b860a4c29812a74bdd0f34e63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4aa900b79a774c08aca8b9f27eceb210",
        "IPY_MODEL_c3dbc0981f5e4cce84b97916e27cb31f",
        "IPY_MODEL_40e9b63b99b747d99cc04e576b076c5a"
       ],
       "layout": "IPY_MODEL_9e8d771fc2c440cd8b1789548d6be832",
       "tabbable": null,
       "tooltip": null
      }
     },
     "78f33cd5bdda44eb9a7cf25d261c90dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b89020b20094b65943b670637569a38",
       "placeholder": "​",
       "style": "IPY_MODEL_826fed99805f45f6a6762dd44b22fb43",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: 100%"
      }
     },
     "80675b3f79024696938b3e4c707358f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8131e2065cee429698b20733518f5201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6389772bc68e4735b21c7528324443d9",
       "placeholder": "​",
       "style": "IPY_MODEL_e39543c1b105484aadd0366dbd106262",
       "tabbable": null,
       "tooltip": null,
       "value": " 269M/269M [00:04&lt;00:00, 47.7MB/s]"
      }
     },
     "826fed99805f45f6a6762dd44b22fb43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "82f50489c069469c898be5d8128fcdc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "82ffc206d83341cc94a357dfc3739f7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89e4c3b290e24a639cae1b10aef37801": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fb5678cd84448d9b8fab4aacab58b2e",
       "placeholder": "​",
       "style": "IPY_MODEL_77f8a09c25024407bc9b3e32001d01c9",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "8a256a3fc414408aa700e2f25feb9411": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b0685cb3d1e46faa17003a4a2cc6667": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d7c3f1b09184cdcbec400eddcfd8832": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90af33c094ea407686af7b92b751ba89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "91720b31bbf54915adfa9152ef56c5c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "938f6fe171424cb7b14fbe16423420e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a84d977f1584bc6b287c112bb061aea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b92377343f7403e86b7457d5d6a2455": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e8d771fc2c440cd8b1789548d6be832": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ea3e7982cda4f4a95c577af51a6c4ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a1b68da3415a48edb4972576a1082a5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_20dc43f7259a4d8e944ac6f5b0c455e9",
        "IPY_MODEL_b9acaa3b1319456fb9f93ea9357e74e2",
        "IPY_MODEL_bac12db015904836825f842a03617466"
       ],
       "layout": "IPY_MODEL_0fe06f5d82a84044afac0bca69a1ec8b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a22789f41b144c31b00b130ae0e1c6a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4c3561901aa4404b5ef72647d6f8475": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a60b9ec57e9d457aa73320b4eb210ad1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a22789f41b144c31b00b130ae0e1c6a6",
       "placeholder": "​",
       "style": "IPY_MODEL_36c1438ff5b146d68b55ea24b924e4b0",
       "tabbable": null,
       "tooltip": null,
       "value": " 801k/801k [00:00&lt;00:00, 13.4MB/s]"
      }
     },
     "a6262271f6a541aba0063d76920da328": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa9ac3de4c064deea3abd7c96c8a5656": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_78f33cd5bdda44eb9a7cf25d261c90dd",
        "IPY_MODEL_6621ad743e9b48888569f34c6e8215c9",
        "IPY_MODEL_06d47d0256a7445789e6e7b325b8d10d"
       ],
       "layout": "IPY_MODEL_4598941ff56d41aab2c7ca2b4e2e6461",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ab13cc30022340539c854085e9d63862": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b181ae1a3c844534b8bef120d21706c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_455c2e1883d94fe7a651826f6036c280",
       "placeholder": "​",
       "style": "IPY_MODEL_9ea3e7982cda4f4a95c577af51a6c4ae",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "b48638c8254344e186ef1d8ebb027bb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9acaa3b1319456fb9f93ea9357e74e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d34efcc9e98942d399aeea01b830526f",
       "max": 831.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_750fbd98661c4bff9d028e6dc4c44bf4",
       "tabbable": null,
       "tooltip": null,
       "value": 831.0
      }
     },
     "bac12db015904836825f842a03617466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9a84d977f1584bc6b287c112bb061aea",
       "placeholder": "​",
       "style": "IPY_MODEL_63e7cef133804e3cbff17482692015f3",
       "tabbable": null,
       "tooltip": null,
       "value": " 831/831 [00:00&lt;00:00, 119kB/s]"
      }
     },
     "bcb9901dab6a4bef9ca94b4d454f98a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c028e70f16d3482eb6bc32c21e7a0ef9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c03917cc38cc4ffda6a05a0a5013244f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c34d67751f4f4062aa10029713d15e13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3990f79c1a3402fa16130dced2ccf22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f428b4d0e2cb4521a70e59dc35476c1d",
        "IPY_MODEL_db77a023d919424eae2d23be13965a37",
        "IPY_MODEL_d4e7bd4dce7c415684e884d68fa724ad"
       ],
       "layout": "IPY_MODEL_d7322bb656834d0da3c1430e86808aa8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c3dbc0981f5e4cce84b97916e27cb31f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f45d98572cc649149e12ccbed32d5d4a",
       "max": 3658.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_efdab0c9063047049bba1ff1a7833296",
       "tabbable": null,
       "tooltip": null,
       "value": 3658.0
      }
     },
     "c60c48178bd74a20be2e10be50eff9d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d34efcc9e98942d399aeea01b830526f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4e7bd4dce7c415684e884d68fa724ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_03e36ce62d2c48b2b7067c3b5723ae28",
       "placeholder": "​",
       "style": "IPY_MODEL_0d3b61b8590644fe910702eb8973ac48",
       "tabbable": null,
       "tooltip": null,
       "value": " 51729/51729 [01:12&lt;00:00, 741.22 examples/s]"
      }
     },
     "d7322bb656834d0da3c1430e86808aa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7d6003273214e7889b3f04b68ab77f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db1cee6d63534659b42ba175a6b300aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db77a023d919424eae2d23be13965a37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b01b84822684a83ada5020aee8105d0",
       "max": 51729.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80675b3f79024696938b3e4c707358f6",
       "tabbable": null,
       "tooltip": null,
       "value": 51729.0
      }
     },
     "e05cb9de452d455d9d4cc9fe64a65e29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0adb909f03642b88c24d9f16e72171a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e39543c1b105484aadd0366dbd106262": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ecfe5418865440bd989366a5bc01fe3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ee8e740a973f4ccba40b9361a2ae9a8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bcb9901dab6a4bef9ca94b4d454f98a0",
       "max": 269060552.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_82f50489c069469c898be5d8128fcdc1",
       "tabbable": null,
       "tooltip": null,
       "value": 269060552.0
      }
     },
     "efdab0c9063047049bba1ff1a7833296": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f428b4d0e2cb4521a70e59dc35476c1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b0685cb3d1e46faa17003a4a2cc6667",
       "placeholder": "​",
       "style": "IPY_MODEL_ff74425c962542b4badb1c08a4884cfb",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "f45d98572cc649149e12ccbed32d5d4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f81a74fe5ec74397a3970911d1363bb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8d7c3f1b09184cdcbec400eddcfd8832",
       "max": 5748.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3963bad3778746c6b9cbd0747c17bd90",
       "tabbable": null,
       "tooltip": null,
       "value": 5748.0
      }
     },
     "f8d543dfe278417e81925c8e6ec8a2f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff74425c962542b4badb1c08a4884cfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
