{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"18793371","cell_type":"markdown","source":"# LLM Classification Finetuning\n\nCompetition: https://www.kaggle.com/competitions/llm-classification-finetuning/overview\n\n## Submission File\n\nFor each ID in the test set, you must predict the probability for each target class. The file should contain a header and have the following format:\n\n```csv\nid,winner_model_a,winner_model_b,winner_tie\n136060,0.33,0,33,0.33\n211333,0.33,0,33,0.33\n1233961,0.33,0,33,0.33\netc\n```\n\nSubmission file must be named `submission.csv` in the `/kaggle/working/` directory.\n\n## Inputs\n\nInput files are in `/kaggle/input/llm-classification-finetuning/` directory if\nrunning on Kaggle.\n\n```\n/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n```","metadata":{}},{"id":"115dc832","cell_type":"code","source":"# Install required packages\n%pip install torch pandas tabulate transformers evaluate peft wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:29:07.460182Z","iopub.execute_input":"2025-06-19T18:29:07.460440Z","iopub.status.idle":"2025-06-19T18:30:34.674403Z","shell.execute_reply.started":"2025-06-19T18:29:07.460420Z","shell.execute_reply":"2025-06-19T18:30:34.673047Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec (from torch)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"id":"76c343d7","cell_type":"code","source":"kaggle_run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE')\nprint(f\"KAGGLE_KERNEL_RUN_TYPE: {kaggle_run_type}\")\n\nON_KAGGLE = kaggle_run_type is not None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:32:43.380392Z","iopub.execute_input":"2025-06-19T18:32:43.381075Z","iopub.status.idle":"2025-06-19T18:32:43.386259Z","shell.execute_reply.started":"2025-06-19T18:32:43.381048Z","shell.execute_reply":"2025-06-19T18:32:43.385381Z"}},"outputs":[{"name":"stdout","text":"KAGGLE_KERNEL_RUN_TYPE: Interactive\n","output_type":"stream"}],"execution_count":3},{"id":"012b4c69","cell_type":"code","source":"# Setup wandb\nimport wandb\nimport os\nfrom kaggle_secrets import UserSecretsClient\n\nos.environ[\"WANDB_PROJECT\"] = \"llm-classification-ft-peft\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n\nif ON_KAGGLE:\n    user_secrets = UserSecretsClient()\n    wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\n    wandb.login(key=wandb_key)\nelse:\n    wandb.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:32:59.593317Z","iopub.execute_input":"2025-06-19T18:32:59.593618Z","iopub.status.idle":"2025-06-19T18:33:00.041879Z","shell.execute_reply.started":"2025-06-19T18:32:59.593596Z","shell.execute_reply":"2025-06-19T18:33:00.040970Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":4},{"id":"f0893984","cell_type":"code","source":"BASE_PATH = '/kaggle/input/llm-classification-finetuning' if ON_KAGGLE else './data/'\n\nprint(f\"Using base path: {BASE_PATH}\")\n\nprint(\"Available files in base path:\")\nfor root, dirs, files in os.walk(BASE_PATH):\n    for file in files:\n        print(f\" - {os.path.join(root, file)}\")\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using base path: ./data/\n","Available files in base path:\n"," - ./data/test.csv\n"," - ./data/sample_submission.csv\n"," - ./data/train.csv\n"]}],"execution_count":4},{"id":"5acea90a","cell_type":"markdown","source":"# Data Inputs\n\nLet's load and look at what we got first for inputs.","metadata":{}},{"id":"e3410a4a","cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n\nsample_submission_df = pd.read_csv(os.path.join(BASE_PATH, 'sample_submission.csv'))","metadata":{},"outputs":[],"execution_count":5},{"id":"b4e59919","cell_type":"code","source":"print(f\"Train DataFrame shape: {train_df.shape}\")\nprint(f\"Test DataFrame shape: {test_df.shape}\")\nprint(f\"Sample Submission DataFrame shape: {sample_submission_df.shape}\")\n\nprint (\"-------------------------\")\n# Print types of each column\nprint(\"\\nColumn types in Train DataFrame:\")\nprint(train_df.dtypes)\n\nprint(\"\\nColumn types in Test DataFrame:\")\nprint(test_df.dtypes)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train DataFrame shape: (57477, 9)\n","Test DataFrame shape: (3, 4)\n","Sample Submission DataFrame shape: (3, 4)\n","-------------------------\n","\n","Column types in Train DataFrame:\n","id                 int64\n","model_a           object\n","model_b           object\n","prompt            object\n","response_a        object\n","response_b        object\n","winner_model_a     int64\n","winner_model_b     int64\n","winner_tie         int64\n","dtype: object\n","\n","Column types in Test DataFrame:\n","id             int64\n","prompt        object\n","response_a    object\n","response_b    object\n","dtype: object\n"]}],"execution_count":6},{"id":"7c30020a","cell_type":"code","source":"print(\"First rows of each DataFrame:\")\n\nprint(\"\\nTrain DataFrame:\")\nprint(train_df.head(1).to_markdown())\n\nprint(\"\\nTest DataFrame:\")\nprint(test_df.head(1).to_markdown())\n\nprint(\"\\nSample Submission DataFrame:\")\nprint(sample_submission_df.head(1).to_markdown())","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First rows of each DataFrame:\n","\n","Train DataFrame:\n","|    |    id | model_a            | model_b    | prompt                                                                                                                                                                | response_a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | response_b                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   winner_model_a |   winner_model_b |   winner_tie |\n","|---:|------:|:-------------------|:-----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------:|-----------------:|-------------:|\n","|  0 | 30192 | gpt-4-1106-preview | gpt-4-0613 | [\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"] | [\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"] | [\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"] |                1 |                0 |            0 |\n","\n","Test DataFrame:\n","|    |     id | prompt                                                                                 | response_a                      | response_b                                                                                                         |\n","|---:|-------:|:---------------------------------------------------------------------------------------|:--------------------------------|:-------------------------------------------------------------------------------------------------------------------|\n","|  0 | 136060 | [\"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\"] | [\"You have two oranges today.\"] | [\"You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\"] |\n","\n","Sample Submission DataFrame:\n","|    |     id |   winner_model_a |   winner_model_b |   winner_tie |\n","|---:|-------:|-----------------:|-----------------:|-------------:|\n","|  0 | 136060 |         0.333333 |         0.333333 |     0.333333 |\n"]}],"execution_count":7},{"id":"8733242b","cell_type":"markdown","source":"## Create Dataset\n\nOk I think we now can load the huggingface stuff to create the datasets from the\npandas dataframes?","metadata":{}},{"id":"4b45f04d","cell_type":"code","source":"from datasets import Dataset \n\n# Convert pandas DataFrame to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\n\n# Split the train dataset into train and validation sets, since the test.csv data only has 3 rows.\ntrain_dataset = train_dataset.train_test_split(test_size=0.1, shuffle=True)\n\n# Can see it's now a DatasetDict with 'train' and 'test' splits\ntrain_dataset","metadata":{},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n","        num_rows: 51729\n","    })\n","    test: Dataset({\n","        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n","        num_rows: 5748\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"id":"87fa7501","cell_type":"markdown","source":"## The model stuff now?\n\nWe need to pick:\n- Model\n- Fine tuning method\n\nLet's start small:\n- smol-lm\n- prompt tuning with `peft`","metadata":{}},{"id":"5737f8e3","cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\ncheckpoint = \"HuggingFaceTB/SmolLM2-135M\"\ndevice = \"cuda\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n\n# why is it none tho\nassert model.config.pad_token_id is None\nassert tokenizer.eos_token is not None, \"Tokenizer must have an eos_token set.\"\n\n# set the pad token to be the same as the eos token\ntokenizer.pad_token = tokenizer.eos_token\n\ninputs = tokenizer.encode(\"def print_hello_world():\", return_tensors=\"pt\").to(device)\noutputs = model.generate(inputs)\n\nprint(\"Generated code:\")\nprint(tokenizer.decode(outputs[0]))\nprint(\"---------------\")\n\nprint(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"name":"stdout","output_type":"stream","text":["Generated code:\n","def print_hello_world():\n","    print(\"Hello World!\")\n","\n","def print_hello_world_with_print():\n","   \n","---------------\n","Memory footprint: 538.06 MB\n"]}],"execution_count":9},{"id":"c3294d80","cell_type":"markdown","source":"## Data format\n\nNote that columns `prompt`, `response_a`, and `response_b` are strings\ncontaining JSON arrays that could have more than 1 element.","metadata":{}},{"id":"df57e8f0","cell_type":"code","source":"import json\n\n# grab the column as a plain Python list of strings\ncol = train_dataset[\"train\"][\"response_a\"]\n\n# find the first row with multiple items\nfirst_multi = next(\n    (\n        (i, arr)\n        for i, raw in enumerate(col)\n        for arr in [json.loads(raw)]\n        if isinstance(arr, list) and len(arr) > 1\n    ),\n    None\n)\n\nif first_multi:\n    i, arr = first_multi\n    print(f\"First row with >1 element: row {i}: {arr}\")\n\n    # now pretty-print the full row at index i\n    row = train_dataset[\"train\"][i].copy()\n\n    # parse the JSON-encoded fields\n    row[\"prompt\"]     = json.loads(row[\"prompt\"])\n    row[\"response_a\"] = arr\n    row[\"response_b\"] = json.loads(row[\"response_b\"])\n\n    print(\"\\nRow detail:\")\n    print(json.dumps(row, indent=2))\nelse:\n    print(\"No rows with >1 element found.\")\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First row with >1 element: row 0: ['Measuring the head circumference of infants and young children is a common medical practice used worldwide to monitor growth and development. This measurement is not specific to Irish children or the UK; it is a routine part of pediatric healthcare in many countries.\\n\\nHead circumference is an important indicator of brain growth and can help healthcare providers identify potential problems such as microcephaly (a condition where the head is smaller than expected) or macrocephaly (a condition where the head is larger than expected). These conditions can be associated with developmental delays or other health issues.\\n\\nIn the UK, the National Health Service (NHS) includes head circumference measurements as part of the regular health and development reviews for all children. These reviews typically take place at various stages during a child\\'s early years, and the measurements are recorded in the child\\'s personal child health record (also known as the \"Red Book\").\\n\\nIf you\\'re asking whether Irish children in the UK are specifically targeted for head circumference measurements for any reason other than routine health checks, then no, there\\'s no policy or practice that singles out Irish children for this measurement. All children, regardless of their background, receive the same standard pediatric care, which includes the monitoring of head circumference.', \"Measuring head circumference is an important part of monitoring a child's growth and development. Here are several key aspects that head circumference can indicate:\\n\\n1. **Normal Growth and Development**: Head circumference measurements can help to ensure that a child's brain is growing properly. It's an important parameter to assess alongside weight and length/height during infancy and early childhood.\\n\\n2. **Developmental Disorders**: Significant deviations from the normal range of head circumference could be indicative of developmental disorders. For example, an unusually small head (microcephaly) could be associated with developmental delays, neurological disorders, or genetic conditions. Conversely, an unusually large head (macrocephaly) might indicate the presence of conditions such as hydrocephalus (accumulation of cerebrospinal fluid within the brain), or other genetic syndromes.\\n\\n3. **Early Identification of Problems**: Regular measurements can help in early identification of potential problems, which can be critical for timely intervention and treatment.\\n\\n4. **Monitoring Progress**: For children with known conditions that affect head size, regular measurements can help monitor the progress of the condition or the effectiveness of treatments.\\n\\n5. **Cranial Abnormalities**: Consistent monitoring can help identify cranial abnormalities, such as craniosynostosis, where the skull bones fuse prematurely, affecting the shape and size of the head and potentially the brain's development.\\n\\n6. **Nutritional Status**: In some cases, head circumference can be an indicator of nutritional status, especially if it correlates with other measurements like weight and height.\\n\\nIt's important to note that head circumference must be interpreted in context. Factors such as the child's age, sex, and ethnicity, as well as parental head sizes, can influence what is considered a normal measurement. Growth charts and percentile curves are used by healthcare providers to compare individual measurements to population averages based on these factors. Deviations from these norms may prompt further investigation, but they are not necessarily indicative of a problem on their own.\", 'In England, children typically have a health review before they start school. This review is part of the Healthy Child Programme, a series of health checks and screenings offered to all children in the UK.\\n\\nThe review that takes place before school is often referred to as the \"school entry health check\" and it is usually carried out during the child\\'s reception year, which is the first year of primary school when children are aged 4 to 5 years old. However, this is not strictly a \"nursery\" check as it coincides with the start of formal education, not pre-school settings.\\n\\nThe purpose of the school entry health check is to ensure that each child is in good health, that any health issues are identified, and that there is an opportunity for parents to discuss any concerns they might have about their child\\'s health or development. The checks usually include assessments of:\\n\\n- Growth (height and weight)\\n- Vision and hearing\\n- General development and well-being\\n- Immunization status\\n\\nThese checks are carried out by school nurses or health visitors. Parents should receive a questionnaire about their child\\'s health, which helps the healthcare professional to understand the child\\'s needs before the review. If any issues are identified, the healthcare professional can refer the child for further assessment or support.\\n\\nIt\\'s important to note that these checks can vary slightly depending on the local authority and the resources available in the area. Parents are typically informed about the health review process by their child\\'s school or their local health services.', \"The Healthy Child Programme in England has evolved over time, adapting to changes in policy, research, and healthcare practices. In 1999, the structure was different from what it is today, but the ethos of child health surveillance and routine developmental checks has been a consistent feature of pediatric care in the UK.\\n\\nDuring the late 1990s, the child health surveillance programme in England included routine developmental checks at various stages in a child's early life. These checks were likely to include an assessment around the time a child would start school, although the exact nature and timing of these checks could have varied by region and the local policies in place at the time.\\n\\nThe checks were designed to ensure that children were developing as expected and to catch any issues early on, such as hearing or vision problems, which could affect a child's learning and development. They were typically carried out in primary care settings, such as GP practices or community clinics, sometimes in conjunction with the school.\\n\\nIt's worth noting that specific policies and practices may have varied between England, Scotland, Wales, and Northern Ireland due to the devolved nature of health services across the UK.\\n\\nIf you are interested in the details of health checks and policies from that time, historical records from the Department of Health, academic research from that period, or archives from health authorities may provide more detailed insights into the child health surveillance programme as it was carried out in 1999.\"]\n","\n","Row detail:\n","{\n","  \"id\": 778373992,\n","  \"model_a\": \"gpt-4-1106-preview\",\n","  \"model_b\": \"mixtral-8x7b-instruct-v0.1\",\n","  \"prompt\": [\n","    \"Is it true that they measure head circumference of Irish children in the uk\",\n","    \"What can it show\",\n","    \"Do they do a checkup for a child before nursery school in England \",\n","    \"Was it so in 1999\"\n","  ],\n","  \"response_a\": [\n","    \"Measuring the head circumference of infants and young children is a common medical practice used worldwide to monitor growth and development. This measurement is not specific to Irish children or the UK; it is a routine part of pediatric healthcare in many countries.\\n\\nHead circumference is an important indicator of brain growth and can help healthcare providers identify potential problems such as microcephaly (a condition where the head is smaller than expected) or macrocephaly (a condition where the head is larger than expected). These conditions can be associated with developmental delays or other health issues.\\n\\nIn the UK, the National Health Service (NHS) includes head circumference measurements as part of the regular health and development reviews for all children. These reviews typically take place at various stages during a child's early years, and the measurements are recorded in the child's personal child health record (also known as the \\\"Red Book\\\").\\n\\nIf you're asking whether Irish children in the UK are specifically targeted for head circumference measurements for any reason other than routine health checks, then no, there's no policy or practice that singles out Irish children for this measurement. All children, regardless of their background, receive the same standard pediatric care, which includes the monitoring of head circumference.\",\n","    \"Measuring head circumference is an important part of monitoring a child's growth and development. Here are several key aspects that head circumference can indicate:\\n\\n1. **Normal Growth and Development**: Head circumference measurements can help to ensure that a child's brain is growing properly. It's an important parameter to assess alongside weight and length/height during infancy and early childhood.\\n\\n2. **Developmental Disorders**: Significant deviations from the normal range of head circumference could be indicative of developmental disorders. For example, an unusually small head (microcephaly) could be associated with developmental delays, neurological disorders, or genetic conditions. Conversely, an unusually large head (macrocephaly) might indicate the presence of conditions such as hydrocephalus (accumulation of cerebrospinal fluid within the brain), or other genetic syndromes.\\n\\n3. **Early Identification of Problems**: Regular measurements can help in early identification of potential problems, which can be critical for timely intervention and treatment.\\n\\n4. **Monitoring Progress**: For children with known conditions that affect head size, regular measurements can help monitor the progress of the condition or the effectiveness of treatments.\\n\\n5. **Cranial Abnormalities**: Consistent monitoring can help identify cranial abnormalities, such as craniosynostosis, where the skull bones fuse prematurely, affecting the shape and size of the head and potentially the brain's development.\\n\\n6. **Nutritional Status**: In some cases, head circumference can be an indicator of nutritional status, especially if it correlates with other measurements like weight and height.\\n\\nIt's important to note that head circumference must be interpreted in context. Factors such as the child's age, sex, and ethnicity, as well as parental head sizes, can influence what is considered a normal measurement. Growth charts and percentile curves are used by healthcare providers to compare individual measurements to population averages based on these factors. Deviations from these norms may prompt further investigation, but they are not necessarily indicative of a problem on their own.\",\n","    \"In England, children typically have a health review before they start school. This review is part of the Healthy Child Programme, a series of health checks and screenings offered to all children in the UK.\\n\\nThe review that takes place before school is often referred to as the \\\"school entry health check\\\" and it is usually carried out during the child's reception year, which is the first year of primary school when children are aged 4 to 5 years old. However, this is not strictly a \\\"nursery\\\" check as it coincides with the start of formal education, not pre-school settings.\\n\\nThe purpose of the school entry health check is to ensure that each child is in good health, that any health issues are identified, and that there is an opportunity for parents to discuss any concerns they might have about their child's health or development. The checks usually include assessments of:\\n\\n- Growth (height and weight)\\n- Vision and hearing\\n- General development and well-being\\n- Immunization status\\n\\nThese checks are carried out by school nurses or health visitors. Parents should receive a questionnaire about their child's health, which helps the healthcare professional to understand the child's needs before the review. If any issues are identified, the healthcare professional can refer the child for further assessment or support.\\n\\nIt's important to note that these checks can vary slightly depending on the local authority and the resources available in the area. Parents are typically informed about the health review process by their child's school or their local health services.\",\n","    \"The Healthy Child Programme in England has evolved over time, adapting to changes in policy, research, and healthcare practices. In 1999, the structure was different from what it is today, but the ethos of child health surveillance and routine developmental checks has been a consistent feature of pediatric care in the UK.\\n\\nDuring the late 1990s, the child health surveillance programme in England included routine developmental checks at various stages in a child's early life. These checks were likely to include an assessment around the time a child would start school, although the exact nature and timing of these checks could have varied by region and the local policies in place at the time.\\n\\nThe checks were designed to ensure that children were developing as expected and to catch any issues early on, such as hearing or vision problems, which could affect a child's learning and development. They were typically carried out in primary care settings, such as GP practices or community clinics, sometimes in conjunction with the school.\\n\\nIt's worth noting that specific policies and practices may have varied between England, Scotland, Wales, and Northern Ireland due to the devolved nature of health services across the UK.\\n\\nIf you are interested in the details of health checks and policies from that time, historical records from the Department of Health, academic research from that period, or archives from health authorities may provide more detailed insights into the child health surveillance programme as it was carried out in 1999.\"\n","  ],\n","  \"response_b\": [\n","    \"I don't have real-time data or personal experiences, but I can tell you that generally, head circumference is not measured based on nationality or ethnicity, but rather as part of a medical examination to assess a child's overall growth and development. In the UK, healthcare professionals may measure the head circumference of children, including those of Irish descent, as part of routine developmental checks. However, it is not a measurement that is specific to Irish children. If you have specific concerns, I would recommend contacting a healthcare professional.\",\n","    \"Measuring head circumference is a simple and non-invasive way for healthcare professionals to assess a child's brain growth and development. Here's what it can show:\\n\\n1. Overall brain growth: A head circumference that falls within normal ranges indicates typical brain growth. Significant deviations from the normal range may suggest abnormal brain growth, which could be a sign of various medical conditions, such as hydrocephalus or microcephaly.\\n\\n2. Developmental delay: A head circumference that is smaller than expected for a child's age may indicate developmental delay, as brain growth is often affected in such cases.\\n\\n3. Genetic conditions: Certain genetic conditions, such as Down syndrome, can be associated with specific head circumference measurements.\\n\\n4. Neurological disorders: Abnormal head circumference measurements may also indicate neurological disorders, such as brain tumors or neurodegenerative diseases.\\n\\n5. Nutritional status: Poor nutrition can impact brain growth, leading to a smaller than expected head circumference.\\n\\nIt is important to note that head circumference measurements should always be interpreted in conjunction with other growth parameters, developmental milestones, and medical history. A single head circumference measurement, when taken out of context, might not provide sufficient information to make a definitive diagnosis.\",\n","    \"Yes, in England, children are typically offered a health check before they start nursery or reception class (the first year of primary school). This health check is called the Reception Class Health Check, and it is part of the Healthy Child Programme. During this check, a school nurse or another healthcare professional will assess the child's overall health, growth, and development. They will usually measure the child's height, weight, and head circumference, as well as check their vision and hearing. The healthcare professional may also discuss any concerns related to the child's health, such as dental health, diet, and physical activity.\\n\\nThe primary aim of the Reception Class Health Check is to identify any potential health issues early on, enabling appropriate interventions and support to be put in place. Parents or guardians will receive information about the check and are encouraged to attend. It is an excellent opportunity for them to discuss any concerns they may have regarding their child's health and well-being with a healthcare professional.\",\n","    \"The Healthy Child Programme, which includes the Reception Class Health Check, was introduced in England in 2009, so it was not in place in 1999. However, various health checks and developmental assessments were available for children before starting school during that time, although they may not have been as standardized or consistent as they are today.\\n\\nIn 1999, the government's National Service Framework for Children, Young People, and Maternity Services outlined the importance of early identification and intervention for children with additional needs. This likely included health checks and developmental assessments before starting school. However, the specific details and implementation of these checks might have varied across different local authorities and healthcare trusts.\\n\\nIf you have specific questions about health checks or developmental assessments for children in 1999, I would recommend consulting a healthcare professional or a historical resource related to child health and development during that time.\"\n","  ],\n","  \"winner_model_a\": 1,\n","  \"winner_model_b\": 0,\n","  \"winner_tie\": 0\n","}\n"]}],"execution_count":10},{"id":"e1bf73e4","cell_type":"markdown","source":"## Preprocessing the Data\n\nNow i want to format the input training data to be an input to the model.\n\nNote that there can be multi-turn conversations.\nThis will be a text input with the following format:\n\n```text\n## Turn 1\n### Prompt\n<prompt[0]>\n\n### Response A\n<response_a[0]>\n\n### Response B\n<response_b[0]>\n\n## Turn 2\n### Prompt\n<prompt[1]>\n\n### Response A\n<response_a[1]>\n\n### Response B\n<response_b[1]>\n\n---\n\nWhich is better?\nAnswer:\n```\n\nWhere `<label>` is one of `a`, `b`, or `tie`.","metadata":{}},{"id":"5535dd3b","cell_type":"code","source":"def preprocess_function(\n    examples,\n    tokenizer,\n    max_length: int = 1024,  # Increased from 512 for multi-turn conversations\n):\n    \"\"\"\n    More efficient preprocessing with better label alignment and proper padding.\n    \"\"\"\n    # 1) Build the text inputs in the desired format\n    inputs = []\n    for prompt_json, response_a_json, response_b_json in zip(\n        examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"]\n    ):\n        # JSON decode the columns to handle multi-turn conversations\n        prompts = json.loads(prompt_json)\n        responses_a = json.loads(response_a_json)\n        responses_b = json.loads(response_b_json)\n        \n        # Build conversation with turn-by-turn format\n        conversation_parts = []\n        for i, (prompt_turn, response_a_turn, response_b_turn) in enumerate(zip(prompts, responses_a, responses_b), 1):\n            turn_text = f\"## Turn {i}\\n\"\n            turn_text += \"### Prompt\\n\"\n            turn_text += f\"{prompt_turn}\\n\\n\"\n\n            turn_text += \"### Response A\\n\"\n            turn_text += f\"{response_a_turn}\\n\\n\"\n\n            turn_text += \"### Response B\\n\"\n            turn_text += f\"{response_b_turn}\\n\"\n\n            conversation_parts.append(turn_text)\n        \n        # Join all turns with separator and add final question\n        conversation = \"\\n---\\n\\n\".join(conversation_parts)\n        input_text = f\"{conversation}\\n\\nWhich is better?\\nAnswer: \"  # Added space after colon\n        inputs.append(input_text)\n\n    # 2) Build the target responses\n    targets = []\n    for wa, wb, wt in zip(\n        examples[\"winner_model_a\"],\n        examples[\"winner_model_b\"],\n        examples[\"winner_tie\"],\n    ):\n        if wa == 1:\n            targets.append(\"a\")\n        elif wb == 1:\n            targets.append(\"b\")\n        elif wt == 1:\n            targets.append(\"tie\")\n        else:\n            raise ValueError(\"Invalid winner values: must be one of a, b, or tie.\")\n\n    # 3) More efficient tokenization - separate input and target tokenization\n    # Tokenize inputs first with no padding to get raw lengths\n    input_tokens = tokenizer(inputs, add_special_tokens=True, padding=False, truncation=False)\n    target_tokens = tokenizer(targets, add_special_tokens=False, padding=False, truncation=False)\n    \n    # 4) Combine and create labels more reliably with proper padding\n    model_inputs = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n    \n    for i, (inp_ids, tgt_ids) in enumerate(zip(input_tokens[\"input_ids\"], target_tokens[\"input_ids\"])):\n        # Combine input + target\n        combined_ids = inp_ids + tgt_ids\n        \n        # Truncate if needed - prioritize keeping the full target\n        if len(combined_ids) > max_length:\n            target_len = len(tgt_ids)\n            if target_len < max_length:  # Only truncate if we can fit the target\n                input_truncated = combined_ids[:max_length - target_len]\n                combined_ids = input_truncated + tgt_ids\n            else:\n                # If target itself is too long, truncate everything\n                combined_ids = combined_ids[:max_length]\n        \n        # Create labels: -100 for input part, actual tokens for target part\n        input_len = len(inp_ids) if len(combined_ids) > len(inp_ids) else len(combined_ids) - len(tgt_ids)\n        input_len = max(0, input_len)  # Ensure non-negative\n        \n        labels = [-100] * input_len + combined_ids[input_len:]\n        \n        # Ensure labels match combined_ids length\n        if len(labels) != len(combined_ids):\n            labels = labels[:len(combined_ids)]\n        \n        # Pad sequences to max_length for consistent batching\n        # Pad input_ids and attention_mask\n        attention_mask = [1] * len(combined_ids)\n        \n        if len(combined_ids) < max_length:\n            padding_length = max_length - len(combined_ids)\n            combined_ids += [tokenizer.pad_token_id] * padding_length\n            attention_mask += [0] * padding_length\n            labels += [-100] * padding_length\n        \n        model_inputs[\"input_ids\"].append(combined_ids)\n        model_inputs[\"labels\"].append(labels)\n        model_inputs[\"attention_mask\"].append(attention_mask)\n    \n    return model_inputs\n\n# Test preprocessing on the first row as an example\nexample = train_dataset[\"train\"].select(range(1))\nexample_preprocessed = preprocess_function(\n    example,\n    tokenizer=tokenizer,\n)\n\nprint(\"Improved Preprocessed example:\")\nprint(\"Input length:\", len(example_preprocessed[\"input_ids\"][0]))\nprint(\"Labels length:\", len(example_preprocessed[\"labels\"][0]))\nprint(\"Lengths match:\", len(example_preprocessed[\"input_ids\"][0]) == len(example_preprocessed[\"labels\"][0]))\n\nprint(\"\\nInput IDs:\")\nprint(\"---------------------\")\nprint(tokenizer.decode(example_preprocessed[\"input_ids\"][0]))\n\n# Remove -100 from labels for display\nlabels = [token_id for token_id in example_preprocessed[\"labels\"][0] if token_id != -100]\nprint(\"---------------------\")\nprint(\"Decoded Labels:\")\nprint(tokenizer.decode(labels))\n\n# Show where labels start\nlabels_full = example_preprocessed[\"labels\"][0]\nfirst_non_ignore = next((i for i, x in enumerate(labels_full) if x != -100), None)\nprint(f\"\\nFirst non-ignore label at position: {first_non_ignore}\")\nif first_non_ignore and first_non_ignore > 5:\n    context_start = max(0, first_non_ignore - 5)\n    context_end = min(len(example_preprocessed[\"input_ids\"][0]), first_non_ignore + 5)\n    print(f\"Context around label start: {tokenizer.decode(example_preprocessed['input_ids'][0][context_start:context_end])}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Improved Preprocessed example:\n","Input length: 1024\n","Labels length: 1024\n","Lengths match: True\n","\n","Input IDs:\n","---------------------\n","## Turn 1\n","### Prompt\n","Is it true that they measure head circumference of Irish children in the uk\n","\n","### Response A\n","Measuring the head circumference of infants and young children is a common medical practice used worldwide to monitor growth and development. This measurement is not specific to Irish children or the UK; it is a routine part of pediatric healthcare in many countries.\n","\n","Head circumference is an important indicator of brain growth and can help healthcare providers identify potential problems such as microcephaly (a condition where the head is smaller than expected) or macrocephaly (a condition where the head is larger than expected). These conditions can be associated with developmental delays or other health issues.\n","\n","In the UK, the National Health Service (NHS) includes head circumference measurements as part of the regular health and development reviews for all children. These reviews typically take place at various stages during a child's early years, and the measurements are recorded in the child's personal child health record (also known as the \"Red Book\").\n","\n","If you're asking whether Irish children in the UK are specifically targeted for head circumference measurements for any reason other than routine health checks, then no, there's no policy or practice that singles out Irish children for this measurement. All children, regardless of their background, receive the same standard pediatric care, which includes the monitoring of head circumference.\n","\n","### Response B\n","I don't have real-time data or personal experiences, but I can tell you that generally, head circumference is not measured based on nationality or ethnicity, but rather as part of a medical examination to assess a child's overall growth and development. In the UK, healthcare professionals may measure the head circumference of children, including those of Irish descent, as part of routine developmental checks. However, it is not a measurement that is specific to Irish children. If you have specific concerns, I would recommend contacting a healthcare professional.\n","\n","---\n","\n","## Turn 2\n","### Prompt\n","What can it show\n","\n","### Response A\n","Measuring head circumference is an important part of monitoring a child's growth and development. Here are several key aspects that head circumference can indicate:\n","\n","1. **Normal Growth and Development**: Head circumference measurements can help to ensure that a child's brain is growing properly. It's an important parameter to assess alongside weight and length/height during infancy and early childhood.\n","\n","2. **Developmental Disorders**: Significant deviations from the normal range of head circumference could be indicative of developmental disorders. For example, an unusually small head (microcephaly) could be associated with developmental delays, neurological disorders, or genetic conditions. Conversely, an unusually large head (macrocephaly) might indicate the presence of conditions such as hydrocephalus (accumulation of cerebrospinal fluid within the brain), or other genetic syndromes.\n","\n","3. **Early Identification of Problems**: Regular measurements can help in early identification of potential problems, which can be critical for timely intervention and treatment.\n","\n","4. **Monitoring Progress**: For children with known conditions that affect head size, regular measurements can help monitor the progress of the condition or the effectiveness of treatments.\n","\n","5. **Cranial Abnormalities**: Consistent monitoring can help identify cranial abnormalities, such as craniosynostosis, where the skull bones fuse prematurely, affecting the shape and size of the head and potentially the brain's development.\n","\n","6. **Nutritional Status**: In some cases, head circumference can be an indicator of nutritional status, especially if it correlates with other measurements like weight and height.\n","\n","It's important to note that head circumference must be interpreted in context. Factors such as the child's age, sex, and ethnicity, as well as parental head sizes, can influence what is considered a normal measurement. Growth charts and percentile curves are used by healthcare providers to compare individual measurements to population averages based on these factors. Deviations from these norms may prompt further investigation, but they are not necessarily indicative of a problem on their own.\n","\n","### Response B\n","Measuring head circumference is a simple and non-invasive way for healthcare professionals to assess a child's brain growth and development. Here's what it can show:\n","\n","1. Overall brain growth: A head circumference that falls within normal ranges indicates typical brain growth. Significant deviations from the normal range may suggest abnormal brain growth, which could be a sign of various medical conditions, such as hydrocephalus or microcephaly.\n","\n","2. Developmental delay: A head circumference that is smaller than expected for a child's age may indicate developmental delay, as brain growth is often affected in such cases.\n","\n","3. Genetic conditions: Certain genetic conditions, such as Down syndrome, can be associated with specific head circumference measurements.\n","\n","4. Neurological disorders: Abnormal head circumference measurements may also indicate neurological disorders, such as brain tumors or neurodegenerative diseases.\n","\n","5. Nutritional status: Poor nutrition can impact brain growth, leading to a smaller than expected head circumference.\n","\n","It is important to note that head circumference measurements should always be interpreted in conjunction with other growth parameters, developmental milestones, and medical history. Aa\n","---------------------\n","Decoded Labels:\n","a\n","\n","First non-ignore label at position: 1023\n","Context around label start:  and medical history. Aa\n"]}],"execution_count":20},{"id":"e9572fbb","cell_type":"code","source":"tokenized = train_dataset.map(\n    lambda ex: preprocess_function(ex, tokenizer),\n    batched=True,\n    # optionally drop old columns\n    remove_columns=train_dataset[\"train\"].column_names,\n)","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56e28565ce09471cb7e971636f4708b9","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/51729 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8528bfd24d84a718636b936cca6214b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/5748 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"execution_count":21},{"id":"4ec08a3e","cell_type":"code","source":"# Let's check the first 2 rows of the tokenized dataset\n\nprint(\"Example rows from the tokenized dataset:\")\nprint(\"--- input_ids ---\")\nprint(tokenizer.decode(tokenized[\"train\"][0][\"input_ids\"], skip_special_tokens=True))\nprint(\"---- labels -----\")\n\n# Clear the -100 padding from labels for display\nlabels = [token_id for token_id in tokenized[\"train\"][0][\"labels\"] if token_id != -100]\nprint(tokenizer.decode(labels))","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Example rows from the tokenized dataset:\n","--- input_ids ---\n","## Turn 1\n","### Prompt\n","Is it true that they measure head circumference of Irish children in the uk\n","\n","### Response A\n","Measuring the head circumference of infants and young children is a common medical practice used worldwide to monitor growth and development. This measurement is not specific to Irish children or the UK; it is a routine part of pediatric healthcare in many countries.\n","\n","Head circumference is an important indicator of brain growth and can help healthcare providers identify potential problems such as microcephaly (a condition where the head is smaller than expected) or macrocephaly (a condition where the head is larger than expected). These conditions can be associated with developmental delays or other health issues.\n","\n","In the UK, the National Health Service (NHS) includes head circumference measurements as part of the regular health and development reviews for all children. These reviews typically take place at various stages during a child's early years, and the measurements are recorded in the child's personal child health record (also known as the \"Red Book\").\n","\n","If you're asking whether Irish children in the UK are specifically targeted for head circumference measurements for any reason other than routine health checks, then no, there's no policy or practice that singles out Irish children for this measurement. All children, regardless of their background, receive the same standard pediatric care, which includes the monitoring of head circumference.\n","\n","### Response B\n","I don't have real-time data or personal experiences, but I can tell you that generally, head circumference is not measured based on nationality or ethnicity, but rather as part of a medical examination to assess a child's overall growth and development. In the UK, healthcare professionals may measure the head circumference of children, including those of Irish descent, as part of routine developmental checks. However, it is not a measurement that is specific to Irish children. If you have specific concerns, I would recommend contacting a healthcare professional.\n","\n","---\n","\n","## Turn 2\n","### Prompt\n","What can it show\n","\n","### Response A\n","Measuring head circumference is an important part of monitoring a child's growth and development. Here are several key aspects that head circumference can indicate:\n","\n","1. **Normal Growth and Development**: Head circumference measurements can help to ensure that a child's brain is growing properly. It's an important parameter to assess alongside weight and length/height during infancy and early childhood.\n","\n","2. **Developmental Disorders**: Significant deviations from the normal range of head circumference could be indicative of developmental disorders. For example, an unusually small head (microcephaly) could be associated with developmental delays, neurological disorders, or genetic conditions. Conversely, an unusually large head (macrocephaly) might indicate the presence of conditions such as hydrocephalus (accumulation of cerebrospinal fluid within the brain), or other genetic syndromes.\n","\n","3. **Early Identification of Problems**: Regular measurements can help in early identification of potential problems, which can be critical for timely intervention and treatment.\n","\n","4. **Monitoring Progress**: For children with known conditions that affect head size, regular measurements can help monitor the progress of the condition or the effectiveness of treatments.\n","\n","5. **Cranial Abnormalities**: Consistent monitoring can help identify cranial abnormalities, such as craniosynostosis, where the skull bones fuse prematurely, affecting the shape and size of the head and potentially the brain's development.\n","\n","6. **Nutritional Status**: In some cases, head circumference can be an indicator of nutritional status, especially if it correlates with other measurements like weight and height.\n","\n","It's important to note that head circumference must be interpreted in context. Factors such as the child's age, sex, and ethnicity, as well as parental head sizes, can influence what is considered a normal measurement. Growth charts and percentile curves are used by healthcare providers to compare individual measurements to population averages based on these factors. Deviations from these norms may prompt further investigation, but they are not necessarily indicative of a problem on their own.\n","\n","### Response B\n","Measuring head circumference is a simple and non-invasive way for healthcare professionals to assess a child's brain growth and development. Here's what it can show:\n","\n","1. Overall brain growth: A head circumference that falls within normal ranges indicates typical brain growth. Significant deviations from the normal range may suggest abnormal brain growth, which could be a sign of various medical conditions, such as hydrocephalus or microcephaly.\n","\n","2. Developmental delay: A head circumference that is smaller than expected for a child's age may indicate developmental delay, as brain growth is often affected in such cases.\n","\n","3. Genetic conditions: Certain genetic conditions, such as Down syndrome, can be associated with specific head circumference measurements.\n","\n","4. Neurological disorders: Abnormal head circumference measurements may also indicate neurological disorders, such as brain tumors or neurodegenerative diseases.\n","\n","5. Nutritional status: Poor nutrition can impact brain growth, leading to a smaller than expected head circumference.\n","\n","It is important to note that head circumference measurements should always be interpreted in conjunction with other growth parameters, developmental milestones, and medical history. Aa\n","---- labels -----\n","a\n"]}],"execution_count":13},{"id":"4e0f660d","cell_type":"markdown","source":"## Now what\n\nNow we have a dataset in the right format with both the inputs and the labels,\nwe can now train wowowow\n\nLet's use the `peft` library to try prompt tuning","metadata":{}},{"id":"5fa2725d","cell_type":"code","source":"from transformers import default_data_collator\n\n# Use the tokenized datasets directly with the Trainer\ntrain_ds = tokenized[\"train\"]\neval_ds = tokenized[\"test\"]\n\nprint(f\"Training dataset size: {len(train_ds)}\")\nprint(f\"Evaluation dataset size: {len(eval_ds)}\")\n\n# Check that all sequences are now the same length\nprint(f\"\\nChecking sequence lengths consistency:\")\nfirst_sample_length = len(train_ds[0][\"input_ids\"])\nprint(f\"First sample length: {first_sample_length}\")\n\n# Check a few more samples to ensure consistency\nfor i in range(min(5, len(train_ds))):\n    length = len(train_ds[i][\"input_ids\"])\n    labels_length = len(train_ds[i][\"labels\"])\n    attention_length = len(train_ds[i][\"attention_mask\"])\n    print(f\"Sample {i}: input_ids={length}, labels={labels_length}, attention_mask={attention_length}\")\n    \n    if length != labels_length or length != attention_length:\n        print(f\"WARNING: Length mismatch in sample {i}\")\n        break\nelse:\n    print(\"All samples have consistent lengths!\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training dataset size: 51729\n","Evaluation dataset size: 5748\n","\n","Checking sequence lengths consistency:\n","First sample length: 1024\n","Sample 0: input_ids=1024, labels=1024, attention_mask=1024\n","Sample 1: input_ids=1024, labels=1024, attention_mask=1024\n","Sample 2: input_ids=1024, labels=1024, attention_mask=1024\n","Sample 3: input_ids=1024, labels=1024, attention_mask=1024\n","Sample 4: input_ids=1024, labels=1024, attention_mask=1024\n","All samples have consistent lengths!\n"]}],"execution_count":22},{"id":"fc1f576d","cell_type":"markdown","source":"## PEFT Config\n\nWe use p-tuning instead of prefix tuning or prompt tuning.\n\n### Why?\nPrefix Tuning is more suitable for generation, while we're doing classification\n\nPrompt tuning is very parameter efficient (e.g. could only need to train 8-16 embeddings) but can underperform.","metadata":{}},{"id":"5e1da1dd","cell_type":"code","source":"from peft import PromptEncoderConfig, get_peft_model\n\n# Improved PEFT configuration with more capacity and regularization\npeft_config = PromptEncoderConfig(\n    task_type=\"CAUSAL_LM\",\n    num_virtual_tokens=50,\n    encoder_hidden_size=256,\n    encoder_dropout=0.1,\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 390,336 || all params: 134,905,344 || trainable%: 0.2893\n"]}],"execution_count":15},{"id":"c2b3e2e8","cell_type":"markdown","source":"## Training\n\nSetup optimizer and learning rate scheduler.","metadata":{}},{"id":"34913291","cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\nimport torch\nfrom typing import Dict, List, Any\n\n# Since we're already padding in preprocessing, use a simpler data collator\n# that doesn't try to pad again\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,  # We're doing causal LM, not masked LM\n    pad_to_multiple_of=None,  # Don't pad again since we already padded in preprocessing\n    return_tensors=\"pt\"\n)\n\n# Improved training arguments with better optimization and scheduling\ntraining_args = TrainingArguments(\n    output_dir=\"./llm-classification-ft-peft-p-tuning/output\",\n    learning_rate=3e-4,              # More conservative learning rate for fine-tuning\n\n    # Smaller batch sizes for memory efficiency\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=4,    # Keep eval batch size higher\n\n    # Increase gradient accumulation to maintain effective batch size\n    gradient_accumulation_steps=16,  # Effective batch size = 2 * 16 = 32\n    num_train_epochs=3,              # More epochs for better convergence\n    weight_decay=0.01,\n    \n    # Better optimization settings\n    warmup_ratio=0.1,                # Warmup for training stability\n    lr_scheduler_type=\"cosine\",      # Cosine annealing instead of linear\n    \n    # Better evaluation and saving strategy\n    eval_strategy=\"steps\",           # Evaluate more frequently\n    eval_steps=100,                  # Evaluate every 100 steps\n    save_strategy=\"steps\", \n    save_steps=100,                  # Save every 100 steps\n    save_total_limit=2,              # Limit checkpoints to save disk space\n\n    # Early stopping and best model selection\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n\n    # Logging and reporting\n    report_to=\"wandb\" if not ON_KAGGLE else None,\n    run_name=\"llm-classification-ft-peft-p-tuning-improved\",\n    logging_steps=10,                # More frequent logging\n\n    # Memory optimization settings\n    dataloader_pin_memory=False,     # Disable pin memory to save GPU memory\n    dataloader_num_workers=0,        # Avoid multiprocessing overhead\n    gradient_checkpointing=True,     # Trade compute for memory\n    fp16=True,                       # Use half precision to reduce memory usage\n\n    # Additional optimizations\n    remove_unused_columns=False,     # Important for custom preprocessing\n    label_names=[\"labels\"],          # Fix for PEFT model warning\n    torch_empty_cache_steps=50,      # Clear cache periodically\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{},"outputs":[],"execution_count":23},{"id":"dea0d3cd","cell_type":"markdown","source":"## Now actually train!","metadata":{}},{"id":"7495ac46","cell_type":"code","source":"# Print current GPU memory usage\nimport torch\n\ndef print_gpu_memory_usage():\n    if torch.cuda.is_available():\n        allocated = torch.cuda.memory_allocated() / 1024**3  # Convert to GB\n        reserved = torch.cuda.memory_reserved() / 1024**3\n        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n        \n        print(\"GPU Memory Usage:\")\n        print(f\"  Allocated: {allocated:.2f} GB\")\n        print(f\"  Reserved:  {reserved:.2f} GB\") \n        print(f\"  Total:     {total:.2f} GB\")\n        print(f\"  Free:      {total - reserved:.2f} GB\")\n        print(f\"  Usage:     {allocated/total*100:.1f}%\")\n    else:\n        print(\"CUDA is not available.\")\n\nprint(\"BEFORE training:\")\nprint_gpu_memory_usage()\n\n# Clear any cached memory\ntorch.cuda.empty_cache()\nprint(\"\\nAfter clearing cache:\")\nprint_gpu_memory_usage()","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BEFORE training:\n","GPU Memory Usage:\n","  Allocated: 0.52 GB\n","  Reserved:  0.53 GB\n","  Total:     22.06 GB\n","  Free:      21.53 GB\n","  Usage:     2.3%\n","\n","After clearing cache:\n","GPU Memory Usage:\n","  Allocated: 0.52 GB\n","  Reserved:  0.53 GB\n","  Total:     22.06 GB\n","  Free:      21.53 GB\n","  Usage:     2.3%\n"]}],"execution_count":17},{"id":"5fe06e37","cell_type":"code","source":"# Memory optimization before training\nimport gc\nimport os\n\n# Clear Python garbage collector\ngc.collect()\n\n# Clear CUDA cache\ntorch.cuda.empty_cache()\n\n# Set PYTORCH environment variable for memory management\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\nprint(\"Pre-training memory optimization complete\")\nprint_gpu_memory_usage()\n\n# Check model's memory footprint\nprint(f\"\\nModel memory footprint: {model.get_memory_footprint() / 1024**3:.2f} GB\")\n\n# Print trainable parameters info\nmodel.print_trainable_parameters()","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Pre-training memory optimization complete\n","GPU Memory Usage:\n","  Allocated: 0.52 GB\n","  Reserved:  0.53 GB\n","  Total:     22.06 GB\n","  Free:      21.53 GB\n","  Usage:     2.3%\n","\n","Model memory footprint: 0.50 GB\n","trainable params: 390,336 || all params: 134,905,344 || trainable%: 0.2893\n"]}],"execution_count":18},{"id":"87698fa4","cell_type":"code","source":"trainer.train()","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4851' max='4851' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4851/4851 7:36:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.826800</td>\n","      <td>1.808750</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.737900</td>\n","      <td>1.739353</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.729500</td>\n","      <td>1.706382</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.668200</td>\n","      <td>1.701184</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.653400</td>\n","      <td>1.684901</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.726500</td>\n","      <td>1.680058</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.744600</td>\n","      <td>1.671225</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.625800</td>\n","      <td>1.669773</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.705000</td>\n","      <td>1.667580</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.642100</td>\n","      <td>1.665027</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>1.664100</td>\n","      <td>1.663530</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.632000</td>\n","      <td>1.662267</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>1.633700</td>\n","      <td>1.660734</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.718400</td>\n","      <td>1.659552</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.726500</td>\n","      <td>1.658673</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.722500</td>\n","      <td>1.659092</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>1.710800</td>\n","      <td>1.657478</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.697000</td>\n","      <td>1.655385</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>1.708400</td>\n","      <td>1.654506</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.678700</td>\n","      <td>1.654296</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>1.639000</td>\n","      <td>1.654111</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>1.705000</td>\n","      <td>1.653334</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>1.643100</td>\n","      <td>1.651434</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>1.667200</td>\n","      <td>1.651641</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.684100</td>\n","      <td>1.650780</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>1.675800</td>\n","      <td>1.649675</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>1.611500</td>\n","      <td>1.648871</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>1.658700</td>\n","      <td>1.649618</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>1.711700</td>\n","      <td>1.648347</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.659600</td>\n","      <td>1.648260</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>1.729600</td>\n","      <td>1.647318</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>1.667800</td>\n","      <td>1.647403</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>1.644900</td>\n","      <td>1.646705</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>1.683400</td>\n","      <td>1.645998</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.601500</td>\n","      <td>1.645495</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>1.665200</td>\n","      <td>1.645079</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>1.684400</td>\n","      <td>1.644421</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>1.639400</td>\n","      <td>1.644038</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>1.683100</td>\n","      <td>1.644113</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.679400</td>\n","      <td>1.643292</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>1.726400</td>\n","      <td>1.643147</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>1.693100</td>\n","      <td>1.642835</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>1.686000</td>\n","      <td>1.642491</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>1.595800</td>\n","      <td>1.642183</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>1.684700</td>\n","      <td>1.642036</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>1.588000</td>\n","      <td>1.641933</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>1.686000</td>\n","      <td>1.641791</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>1.652000</td>\n","      <td>1.641754</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-100)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-200)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-200)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-300)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-300)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-400)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-400)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-500)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-500)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-600)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-600)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-700)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-700)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-800)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-800)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-900)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-900)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1000)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1000)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1100)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1100)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1200)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1200)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1300)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1300)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1400)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1400)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1500)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1500)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1600)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1600)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1700)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1700)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1800)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1800)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1900)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-1900)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2000)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2000)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2100)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2100)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2200)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2200)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2300)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2300)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2400)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2400)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2500)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2500)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2600)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2600)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2700)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2700)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2800)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2800)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2900)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-2900)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3000)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3000)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3100)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3100)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3200)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3200)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3300)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3300)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3400)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3400)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3500)... Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3500)... Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3600)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3600)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3700)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3700)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3800)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3800)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3900)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-3900)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4000)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4000)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4100)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4100)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4200)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4200)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4300)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4300)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4400)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4400)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4500)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4500)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4600)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4600)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4700)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4700)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4800)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4800)... Done. 0.0s\n","Done. 0.0s\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4851)... \u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llm-classification-ft-peft-p-tuning/output/checkpoint-4851)... Done. 0.0s\n","Done. 0.0s\n"]},{"data":{"text/plain":["TrainOutput(global_step=4851, training_loss=1.683607234042641, metrics={'train_runtime': 27405.486, 'train_samples_per_second': 5.663, 'train_steps_per_second': 0.177, 'total_flos': 1.0126169534221517e+17, 'train_loss': 1.683607234042641, 'epoch': 3.0})"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"execution_count":24},{"id":"021ef7e1","cell_type":"code","source":"wandb.finish()","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Unable to save notebook session history.\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▄▆▇▆▆▂▁▂▁▁▁▂▂▂▁▂▁▁▁▂▂▁▁▁▁▁▂▆▆▇█▇█▇█▇▆▇</td></tr><tr><td>eval/samples_per_second</td><td>▅▄▅▂▂▃▃▇▇▇█▇█▇▇▇█▇▇██▇▇████▇▆▂▂▂▁▂▁▁▁▂▃▂</td></tr><tr><td>eval/steps_per_second</td><td>▅▄▅▂▂▃▃▇▇▇█▇█▇▇▇█▇▇██▇▇████▇▆▂▂▂▁▂▁▁▁▂▃▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▄▅▃█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▇█████████▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▇▅▄▅▅▇▃▅▁▆▅▄▆█▄▅▃▅▂▆▃▂▃▅▃▅▂▅▃▁▂▄▂▅▄▄▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.64175</td></tr><tr><td>eval/runtime</td><td>249.4453</td></tr><tr><td>eval/samples_per_second</td><td>23.043</td></tr><tr><td>eval/steps_per_second</td><td>5.761</td></tr><tr><td>total_flos</td><td>1.0126169534221517e+17</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>4851</td></tr><tr><td>train/grad_norm</td><td>0.43003</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7138</td></tr><tr><td>train_loss</td><td>1.68361</td></tr><tr><td>train_runtime</td><td>27405.486</td></tr><tr><td>train_samples_per_second</td><td>5.663</td></tr><tr><td>train_steps_per_second</td><td>0.177</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">llm-classification-ft-peft-p-tuning-improved</strong> at: <a href='https://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft/runs/70ksmmq1' target=\"_blank\">https://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft/runs/70ksmmq1</a><br> View project at: <a href='https://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft' target=\"_blank\">https://wandb.ai/drklee3-kava-labs/llm-classification-ft-peft</a><br>Synced 5 W&B file(s), 0 media file(s), 355 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250619_011244-70ksmmq1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"execution_count":25},{"id":"131082c1","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"355ca9cc","cell_type":"code","source":"# Save the model and tokenizer\n\ntrainer.save_model(\"./llm-classification-ft-peft-p-tuning-improved\")","metadata":{},"outputs":[{"data":{"text/plain":["('./llm-classification-ft-peft-p-tuning-improved/tokenizer_config.json',\n"," './llm-classification-ft-peft-p-tuning-improved/special_tokens_map.json',\n"," './llm-classification-ft-peft-p-tuning-improved/vocab.json',\n"," './llm-classification-ft-peft-p-tuning-improved/merges.txt',\n"," './llm-classification-ft-peft-p-tuning-improved/added_tokens.json',\n"," './llm-classification-ft-peft-p-tuning-improved/tokenizer.json')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"id":"3f4e73e5","cell_type":"markdown","source":"## Inference Time\n\nNow we have a fine tuned model, we can use it to make predictions on the test\nset to see how well (or more likely how poorly) it does.","metadata":{}},{"id":"201a294f","cell_type":"code","source":"# Load the best model after training\nbest_model = AutoModelForCausalLM.from_pretrained(\n    training_args.output_dir,\n    low_cpu_mem_usage=True,  # Use low memory loading\n)","metadata":{},"outputs":[],"execution_count":null}]}